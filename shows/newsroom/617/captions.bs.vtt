WEBVTT
Kind: captions
Language: bs

00:00:00.030 --> 00:00:05.009
 evo priča koje su pokrivale ovo 

00:00:01.949 --> 00:00:06.960
 sedmicu u TV redakciji kategorije 5, to je 

00:00:05.009 --> 00:00:08.880
 odlučio da će Facebook biti kažnjen a 

00:00:06.960 --> 00:00:11.460
 pet milijardi dolara 

00:00:08.880 --> 00:00:14.040
 Cambridge analitički skandal u potpunosti 

00:00:11.460 --> 00:00:17.060
 interaktivni Doktor Tko VR igra 

00:00:14.040 --> 00:00:19.439
 ruba vremena stiže u septembru 

00:00:17.060 --> 00:00:21.420
 stvoren sistem veštačke inteligencije 

00:00:19.439 --> 00:00:23.670
 istraživača sa Univerziteta u 

00:00:21.420 --> 00:00:27.300
 Kalifornija je rešila Rubikovu kocku 

00:00:23.670 --> 00:00:30.779
 u nešto više od sekunde i Intel ima 

00:00:27.300 --> 00:00:33.960
 otkrio svoj novi AI sistem Hawaii Beach 

00:00:30.779 --> 00:00:36.809
 to je neuromorfni kompjuter sposoban 

00:00:33.960 --> 00:00:38.280
 simulirajući ih osam miliona neurona 

00:00:36.809 --> 00:00:41.280
 priče dolaze 

00:00:38.280 --> 00:00:44.340
 ne idite nigde, ovo je kategorija 5 

00:00:41.280 --> 00:00:50.640
 TV redakcija koja pokriva vrhunsku tehnologiju 

00:00:44.340 --> 00:00:52.680
 priče je linux kod nas sam sasha 

00:00:50.640 --> 00:00:54.809
 Rickman i on su pročitali glavne priče 

00:00:52.680 --> 00:00:56.489
 nakon ove nedelje je odlučeno 

00:00:54.809 --> 00:00:57.870
 Facebook će biti kažnjen sa ogromnim 5 

00:00:56.489 --> 00:01:00.059
 milijarde dolara preko Kembridža 

00:00:57.870 --> 00:01:02.370
 analitički skandal Potrošač 

00:01:00.059 --> 00:01:05.010
 Agencija za zaštitu u SAD-u 

00:01:02.370 --> 00:01:07.320
 Trgovinska komisija FTC je počela istragu 

00:01:05.010 --> 00:01:09.479
 Facebook u martu 2018. godine 

00:01:07.320 --> 00:01:11.970
 izveštaje koje je Cambridge analitički imao 

00:01:09.479 --> 00:01:14.549
 pristupio podacima od nekoliko desetina miliona dolara 

00:01:11.970 --> 00:01:16.759
 svojim korisnicima kao što se ispostavlja ako 

00:01:14.549 --> 00:01:20.100
 politička konsultantska firma je uspjela 

00:01:16.759 --> 00:01:23.580
 nepropisno dobija podatke do 87 

00:01:20.100 --> 00:01:26.070
 milion korisnika Facebooka 

00:01:23.580 --> 00:01:28.619
 fokusiran na to da li je Facebook prekršio 

00:01:26.070 --> 00:01:30.990
 sporazum iz 2011. godine u kojem je i bio 

00:01:28.619 --> 00:01:34.170
 obavezno da obavesti korisnike i 

00:01:30.990 --> 00:01:37.170
 dobiti izričiti pristanak za dijeljenje svojih podataka 

00:01:34.170 --> 00:01:39.030
 u tri do dva glasa rekord 5 

00:01:37.170 --> 00:01:41.939
 milijarda dolara je odobreno 

00:01:39.030 --> 00:01:43.680
 od strane FTC-a kazna još uvijek mora biti 

00:01:41.939 --> 00:01:45.930
 finaliziran od strane Ministarstva pravde 

00:01:43.680 --> 00:01:49.290
 Civilno odeljenje i nije jasno kako 

00:01:45.930 --> 00:01:51.420
 dugo ovo može potrajati ako se potvrdi 

00:01:49.290 --> 00:01:54.540
 biti najveća kazna koja je ikada naplaćena 

00:01:51.420 --> 00:01:56.969
 FTC na tehnološkoj kompaniji Facebook je bio 

00:01:54.540 --> 00:01:59.280
 očekujući da će to reći investitorima 

00:01:56.969 --> 00:02:01.469
 April da je ostavio po strani većinu 

00:01:59.280 --> 00:02:04.170
 novac što znači da firma neće 

00:02:01.469 --> 00:02:07.259
 osećam mnogo dodatnog finansijskog opterećenja 

00:02:04.170 --> 00:02:09.629
 ova kazna ono što još ne znamo 

00:02:07.259 --> 00:02:12.180
 koje dodatne mjere mogu biti postavljene 

00:02:09.629 --> 00:02:13.410
 na kompaniju kao što je povećana privatnost 

00:02:12.180 --> 00:02:14.640
 nadzor ili 

00:02:13.410 --> 00:02:16.500
 ako bude bilo kakvih ličnih 

00:02:14.640 --> 00:02:19.260
 reperkusije za šefa kompanije 

00:02:16.500 --> 00:02:21.630
 izvršni Mark Zuckerberg naselje 

00:02:19.260 --> 00:02:23.730
 što iznosi oko četvrtinu. \ t 

00:02:21.630 --> 00:02:25.710
 godišnja dobit kompanije 

00:02:23.730 --> 00:02:27.450
 reignite kritike od onih koji kažu 

00:02:25.710 --> 00:02:29.270
 da kazna nije mnogo više od a 

00:02:27.450 --> 00:02:33.180
 šamaranje na ručni zglob 

00:02:29.270 --> 00:02:37.550
 hmm pet milijardi dolara nije šamar 

00:02:33.180 --> 00:02:40.110
 na zglobu se malo povećava 

00:02:37.550 --> 00:02:44.250
 $ 2,00 je velika kazna 

00:02:40.110 --> 00:02:46.410
 to je da, mislim da ne mislim 

00:02:44.250 --> 00:02:49.740
 da će ignorisati kaznu 

00:02:46.410 --> 00:02:51.570
 Tačno, ali nastavili su već 

00:02:49.740 --> 00:02:54.990
 većinu tog novca možemo odneti 

00:02:51.570 --> 00:02:58.380
 ne kažem da je imao pristup većini Oh novac uzeti 

00:02:54.990 --> 00:03:02.160
 da iz našeg viška želiš 

00:02:58.380 --> 00:03:03.900
 da bi vas bolelo da idete dalje od toga 

00:03:02.160 --> 00:03:06.650
 iskreno mislim da je to bio šamar 

00:03:03.900 --> 00:03:09.300
 zglob i čitao sam članak 

00:03:06.650 --> 00:03:11.190
 došlo je do skoka dionica nakon 

00:03:09.300 --> 00:03:14.310
 fino je najavljen mm-hmm zašto nemam 

00:03:11.190 --> 00:03:15.540
 ali je skoro skok dionica 

00:03:14.310 --> 00:03:20.550
 proizvodi istu količinu novca kao i oni 

00:03:15.540 --> 00:03:22.500
 su kažnjeni Wow ljudi su tako zaljubljeni 

00:03:20.550 --> 00:03:24.060
 to je kao Oh Papa dobro prokleto 

00:03:22.500 --> 00:03:25.970
 Facebook mi smo upravo vratili novac 

00:03:24.060 --> 00:03:28.380
 kao što je Timmy glup 

00:03:25.970 --> 00:03:30.420
 sa pravnog stanovišta kao što ako 

00:03:28.380 --> 00:03:32.280
 oni su to postigli 

00:03:30.420 --> 00:03:34.050
 govoreći: Da, ništa nisu postigli 

00:03:32.280 --> 00:03:36.060
 praktično pravo šta će uraditi 

00:03:34.050 --> 00:03:39.959
 da će pet milijardi dolara ići 

00:03:36.060 --> 00:03:42.709
 u savezne kase hmm šta ja želim 

00:03:39.959 --> 00:03:46.680
 znati da će to proizvesti 

00:03:42.709 --> 00:03:48.810
 tužbe kao da će neko reći da sam ja 

00:03:46.680 --> 00:03:50.880
 tužio sam vas sada Facebook 

00:03:48.810 --> 00:03:52.680
 da budem iluzija tih žrtava da ja 

00:03:50.880 --> 00:03:54.810
 bio je žrtva i moj život je bio pogođen 

00:03:52.680 --> 00:03:57.530
 jer sada vidim ove reklame 

00:03:54.810 --> 00:04:01.080
 koje nikad nisam želio vidjeti prije nego što želim 

00:03:57.530 --> 00:04:02.550
 deset miliona dolara, ali mislim da mogu 

00:04:01.080 --> 00:04:05.610
 vidi odelo iz akcije 

00:04:02.550 --> 00:04:09.660
 hmm, mislim da će i to da se podigne 

00:04:05.610 --> 00:04:11.790
 Verovatno ne baš, ali pravo 

00:04:09.660 --> 00:04:14.400
 Iskreno, sa svim tim novcem 

00:04:11.790 --> 00:04:16.470
 Facebook čini i sve nametljivo 

00:04:14.400 --> 00:04:17.940
 priroda koju su izgradili 

00:04:16.470 --> 00:04:20.250
 kompanija oko mene mislim pet miliona ili 

00:04:17.940 --> 00:04:22.289
 pet miliona je šala što bi ti 

00:04:20.250 --> 00:04:24.860
 stavio sam ga na to 

00:04:22.289 --> 00:04:24.860
 petnaest 

00:04:24.900 --> 00:04:31.870
 Ne bih se borio sa 15.000.000.000 dolara 

00:04:28.599 --> 00:04:34.870
 Da, ali druga stvar sam ja 

00:04:31.870 --> 00:04:36.039
 mislim da je ovo naselje koje ne mislim 

00:04:34.870 --> 00:04:37.539
 mislim da je to bila prava novčana kazna 

00:04:36.039 --> 00:04:42.490
 prekinuo je ugovor sa sobom kako bi znali šta 

00:04:37.539 --> 00:04:44.319
 dolazila je jedna pozitivna 1/4 

00:04:42.490 --> 00:04:47.050
 godišnjih zarada ako sam morao da potrošim 

00:04:44.319 --> 00:04:50.680
 jedna četvrtina moje zarade od kazne 

00:04:47.050 --> 00:04:57.400
 Jedem mr. Mislim da je to rezanci 

00:04:50.680 --> 00:05:00.550
 mi smo u drugom poreskom razredu 

00:04:57.400 --> 00:05:03.219
 razmisli o tome da je kazna 1/4 njihove 

00:05:00.550 --> 00:05:06.030
 godišnji prihod samo od prodaje 

00:05:03.219 --> 00:05:09.940
 lični podaci to rade 

00:05:06.030 --> 00:05:12.340
 da Ja branim Facebook zapamti I 

00:05:09.940 --> 00:05:15.280
 Nisam više ni na Facebooku to je 

00:05:12.340 --> 00:05:17.110
 koliko sam bio tužan zbog svega ovoga 

00:05:15.280 --> 00:05:19.389
 kršenje privatnosti da i ne mislim 

00:05:17.110 --> 00:05:21.909
 Zuckerberg je van prozora i nije 

00:05:19.389 --> 00:05:25.000
 Neću ga dotaknuti, neću vam reći šta 

00:05:21.909 --> 00:05:26.500
 kao korisnik kao programer u cjelini 

00:05:25.000 --> 00:05:29.770
 Kembridž analitička stvar što to radi 

00:05:26.500 --> 00:05:31.060
 za mene je strogo frustriran 

00:05:29.770 --> 00:05:33.159
 gde sam sve otkazao 

00:05:31.060 --> 00:05:37.779
 Facebook usluge unutar moje kompanije 

00:05:33.159 --> 00:05:39.580
 baš kao što više ne pružam Facebook 

00:05:37.779 --> 00:05:41.409
 usluge našim klijentima Imao sam nekoga 

00:05:39.580 --> 00:05:42.789
 čak me je i pitao da postavim 

00:05:41.409 --> 00:05:44.949
 Instagram profil i rekao sam ići 

00:05:42.789 --> 00:05:46.479
 negdje drugdje neću to učiniti, nisam 

00:05:44.949 --> 00:05:48.909
 Ja se ne bavim tom kompanijom 

00:05:46.479 --> 00:05:50.289
 više vidi tu stvar 

00:05:48.909 --> 00:05:51.460
 Malo mi smeta priču 

00:05:50.289 --> 00:05:54.580
 i znam da moramo da pređemo na broj 

00:05:51.460 --> 00:05:57.099
 Jednu koju vidite kada je Elon Musk napravio svoj 

00:05:54.580 --> 00:05:59.440
 cvrkutati o rezanju nekog posla u inostranstvu 

00:05:57.099 --> 00:06:01.180
 ili nešto što se nikada nije ostvarilo 

00:05:59.440 --> 00:06:03.819
 odjednom je došao iz zanata 

00:06:01.180 --> 00:06:05.349
 Komisija je imala godinu sankcija za 

00:06:03.819 --> 00:06:07.449
 Twitter i on je imao nekoga kao 

00:06:05.349 --> 00:06:09.370
 etičko lice ga prati i kao da 

00:06:07.449 --> 00:06:11.319
 kao da je tu bio advokat 

00:06:09.370 --> 00:06:13.599
 kao da je tu bila velika stvar mm-hmm 

00:06:11.319 --> 00:06:14.979
 dok Facebook oslobađa milione 

00:06:13.599 --> 00:06:16.210
 lične podatke ljudi i oni 

00:06:14.979 --> 00:06:19.960
 idite da nam platite nešto novca 

00:06:16.210 --> 00:06:21.729
 mm-hmm kao gdje je utjecaj na 

00:06:19.960 --> 00:06:22.990
 Da, mislim da bi trebalo da postoji 

00:06:21.729 --> 00:06:25.020
 mnogo više toga dolazi s njim 

00:06:22.990 --> 00:06:27.610
 mislim da je uticaj na kompaniju 

00:06:25.020 --> 00:06:29.830
 kompanije govore da se ne bavim time 

00:06:27.610 --> 00:06:32.560
 Facebook više, ali pogledaj ja ne kupujem 

00:06:29.830 --> 00:06:35.289
 oglasni prostor na Facebook-u sada smo mi 

00:06:32.560 --> 00:06:36.969
 imati facebook profil na Facebook stranici 

00:06:35.289 --> 00:06:37.650
 za kategoriju 5 TV jer postoji 

00:06:36.969 --> 00:06:39.690
 mnogo 

00:06:37.650 --> 00:06:42.630
 i zato želimo da bude dostupan 

00:06:39.690 --> 00:06:44.910
 vi, ali lično, ja je ne koristim i ja 

00:06:42.630 --> 00:06:46.680
 ne podržavam ga kao da je to ono što 

00:06:44.910 --> 00:06:48.900
 Izgleda da je ponovo eksplodirala ove nedelje 

00:06:46.680 --> 00:06:50.310
 mm-hmm i sve lične podatke 

00:06:48.900 --> 00:06:52.860
 oduzeti od ljudi jednostavno ne 

00:06:50.310 --> 00:06:55.229
 briga kao što javnost nije briga, ali ja 

00:06:52.860 --> 00:06:57.300
 shvatam da je to široka traka da ne 

00:06:55.229 --> 00:07:00.479
 volim generalizirati i za to se izvinjavam 

00:06:57.300 --> 00:07:02.820
 generalizaciju zato što možda jeste 

00:07:00.479 --> 00:07:04.229
 govoreći: "Ne brinem se, apsolutno mi je stalo." 

00:07:02.820 --> 00:07:05.699
 Otkazao sam svoj račun ili možda ja 

00:07:04.229 --> 00:07:07.620
 nisam se čak ni prijavio za jednu cuz jer nisam 

00:07:05.699 --> 00:07:10.740
 slažete se sa njihovim Uslovima pružanja usluge, ali 

00:07:07.620 --> 00:07:13.169
 Činjenica ostaje takva kakva smo u a 

00:07:10.740 --> 00:07:16.350
 drugačiji period nego što smo bili deset godina 

00:07:13.169 --> 00:07:18.870
 pre sada su tipovi podataka podaci lopovluk 

00:07:16.350 --> 00:07:21.510
 koje se dešavaju u stvarima kao što su društveni 

00:07:18.870 --> 00:07:24.150
 mediji nisu postojali prije deset godina i tako 

00:07:21.510 --> 00:07:27.210
 zakon to mora da nadoknadi 

00:07:24.150 --> 00:07:29.130
 kao da postoji mnogo različitih stvari koje možemo 

00:07:27.210 --> 00:07:32.070
 razgovaramo o MP duplo-a možemo razgovarati 

00:07:29.130 --> 00:07:36.210
 o oh yeah poput svih ovih stvari i 

00:07:32.070 --> 00:07:39.300
 i još nisu stigli i možda 

00:07:36.210 --> 00:07:40.650
 to je barem jedan korak barem možda 

00:07:39.300 --> 00:07:42.510
 ne o Facebooku možda ne ide 

00:07:40.650 --> 00:07:45.210
 da ih upropastim, ali možda će ići 

00:07:42.510 --> 00:07:47.310
 zaštitite korisnike od sljedećeg velikog kršenja 

00:07:45.210 --> 00:07:50.099
 jer je sledeći veliki H još uvek na 

00:07:47.310 --> 00:07:51.710
 nadamo se nadamo se da ne znamo 

00:07:50.099 --> 00:07:55.260
 velike slike 

00:07:51.710 --> 00:07:57.210
 potpuno interaktivni doktor koji VR igra 

00:07:55.260 --> 00:07:59.820
 ušla je ivica vremena 

00:07:57.210 --> 00:08:01.560
 Septembar je liječnik bačen 

00:07:59.820 --> 00:08:03.780
 kroz vreme do kraja univerzuma 

00:08:01.560 --> 00:08:05.930
 virus koji preti da se raspada 

00:08:03.780 --> 00:08:08.669
 sama stvarnost je oslobođena 

00:08:05.930 --> 00:08:10.440
 igrači mogu pilotirati TARDIS na a 

00:08:08.669 --> 00:08:12.630
 putovanje kroz svetove oboje poznato 

00:08:10.440 --> 00:08:15.030
 i čudno da se oporavi serija 

00:08:12.630 --> 00:08:17.130
 moćni vremenski kristali koji se mogu popraviti 

00:08:15.030 --> 00:08:19.979
 prostor-vreme i na kraju spasiti 

00:08:17.130 --> 00:08:23.190
 samom svemiru nakon nedavnog 

00:08:19.979 --> 00:08:25.680
 otkrivaju animirano VR iskustvo 

00:08:23.190 --> 00:08:28.260
 Doktor Koji je pobjegao novi film 

00:08:25.680 --> 00:08:29.729
 dugometražni Doktor Who VR video igra 

00:08:28.260 --> 00:08:32.250
 dolazi ovog septembra 

00:08:29.729 --> 00:08:34.589
 objavljen od strane play stack-a i razvijen od strane 

00:08:32.250 --> 00:08:37.320
 teorija labirinta Doktor Ko na rubu 

00:08:34.589 --> 00:08:39.900
 vrijeme će prenijeti fanove na globalno 

00:08:37.320 --> 00:08:41.969
 dragi svet vanzemaljaca i misterija 

00:08:39.900 --> 00:08:44.010
 Pitam se da ih pustimo da se ukrcaju 

00:08:41.969 --> 00:08:46.470
 potpuno novi i potpuno interaktivni 

00:08:44.010 --> 00:08:49.589
 avantura inspirirana 55-godišnjom emisijom 

00:08:46.470 --> 00:08:51.490
 istorije i glume doktora 

00:08:49.589 --> 00:08:55.210
 inkarnacija koju je igrao Jody 

00:08:51.490 --> 00:08:57.630
 Whitaker je naoružan ikoničnim zvukom 

00:08:55.210 --> 00:08:59.920
 šrafciger plan igrači će riješiti 

00:08:57.630 --> 00:09:01.990
 zagonetke koje savijaju um 

00:08:59.920 --> 00:09:04.570
 klasična čudovišta i susret sa novim 

00:09:01.990 --> 00:09:06.670
 horizonti u potrazi za doktorom 

00:09:04.570 --> 00:09:08.680
 i poraziti moćnu silu 

00:09:06.670 --> 00:09:11.640
 preti da uništi tkaninu 

00:09:08.680 --> 00:09:15.640
 oni će se suočiti sa zloglasnim 

00:09:11.640 --> 00:09:19.180
 Daleks felix Daleks da Dalek imamo 

00:09:15.640 --> 00:09:21.850
 jedan ovde na setu ili poznat 

00:09:19.180 --> 00:09:24.610
 lica iz svemira doktora plus 

00:09:21.850 --> 00:09:26.620
 neki novi, nikad ranije viđeni 

00:09:24.610 --> 00:09:29.080
 čudovišta dok putuju kroz zapanjujuće 

00:09:26.620 --> 00:09:33.240
 filmske sredine koje zaista donose 

00:09:29.080 --> 00:09:39.150
 predstava je u redu, pa prije svega 

00:09:33.240 --> 00:09:39.150
 to je dolar kao da, čekam 

00:09:39.330 --> 00:09:43.900
 istrijebiti glumca u redu tako da su moja djeca 

00:09:42.640 --> 00:09:45.970
 biti ću oduševljen time 

00:09:43.900 --> 00:09:48.640
 oduševljen ovim prije svega 

00:09:45.970 --> 00:09:52.270
 priča zvuči kao moj svakodnevni život 

00:09:48.640 --> 00:09:53.980
 Zvuči prilično cool ovih dana 

00:09:52.270 --> 00:09:55.840
 oni to mogu mnogo i Jodie 

00:09:53.980 --> 00:09:57.550
 Whittaker je zapravo uključen u 

00:09:55.840 --> 00:10:00.070
 stvarna igra će biti zabavna 

00:09:57.550 --> 00:10:03.250
 za navijače Jodie Whittaker i ući u 

00:10:00.070 --> 00:10:06.060
 Jedanaesti fanovi doktora tako da je ovo 

00:10:03.250 --> 00:10:08.230
 sjajno da i imamo i Orville 

00:10:06.060 --> 00:10:10.990
 interaktivno iskustvo ventilatora koje je 

00:10:08.230 --> 00:10:13.330
 dolazi u par u sledećem paru 

00:10:10.990 --> 00:10:15.520
 nedelja kao što će se uskoro dogoditi 

00:10:13.330 --> 00:10:18.040
 već na Steam-u, tako da tražimo 

00:10:15.520 --> 00:10:20.500
 Orville, tako da gledamo kao neki 

00:10:18.040 --> 00:10:23.950
 velike naučno-fantastične emisije su sada 

00:10:20.500 --> 00:10:26.500
 će biti igrica VR igara da to je 

00:10:23.950 --> 00:10:29.110
 kul je jako cool tako gledati naprijed 

00:10:26.500 --> 00:10:32.470
 na ovo - Hvala Sasha ti nisi 

00:10:29.110 --> 00:10:34.600
 VR sistem veštačke inteligencije 

00:10:32.470 --> 00:10:37.000
 stvorili istraživači na Univerzitetu 

00:10:34.600 --> 00:10:40.960
 Kalifornije je riješio Rubik 

00:10:37.000 --> 00:10:43.990
 Kocka u samo preko druge duboke kocke a 

00:10:40.960 --> 00:10:46.150
 je algoritam nazvan završen 3d 

00:10:43.990 --> 00:10:49.620
 logička slagalica koja je oporezovala 

00:10:46.150 --> 00:10:52.450
 ljudi otkako je izumljen 1974. godine 

00:10:49.620 --> 00:10:54.640
 Profesor Pierre Baldy koji je autor 

00:10:52.450 --> 00:10:58.240
 izveštaj o prirodnoj mašinskoj inteligenciji 

00:10:54.640 --> 00:11:00.550
 je rekao citat je naučio sam 

00:10:58.240 --> 00:11:01.960
 istraživači su primijetili da je njegova strategija 

00:11:00.550 --> 00:11:04.790
 veoma različita od načina na koji ljudi 

00:11:01.960 --> 00:11:08.210
 bavio se slagalicom profesorom Baldijem 

00:11:04.790 --> 00:11:09.890
 kaže da je moja najbolja pretpostavka da je forma a 

00:11:08.210 --> 00:11:13.070
 Razmišljanja su potpuno drugačija 

00:11:09.890 --> 00:11:15.350
 iz ljudskog citiranja kompjutera 

00:11:13.070 --> 00:11:17.330
 algoritam nije prvi ili 

00:11:15.350 --> 00:11:19.910
 najbrže ne-ljudsko za rješavanje zagonetke 

00:11:17.330 --> 00:11:21.590
 ta čast ide u sistem osmišljen na 

00:11:19.910 --> 00:11:24.650
 Massachusetts Institute of 

00:11:21.590 --> 00:11:27.350
 Tehnologija nazvana min 

00:11:24.650 --> 00:11:30.860
 algoritam koji je riješio slagalicu tri 

00:11:27.350 --> 00:11:32.990
 puta brže, ali taj sistem nije koristio 

00:11:30.860 --> 00:11:35.450
 neuronska mreža koja oponaša način 

00:11:32.990 --> 00:11:37.700
 ljudski mozak ili strojno učenje 

00:11:35.450 --> 00:11:39.850
 kontrastne tehnike su programirane 

00:11:37.700 --> 00:11:42.410
 posebno za rješavanje zagonetke 

00:11:39.850 --> 00:11:44.510
 stvaranje sistema na koji se uči 

00:11:42.410 --> 00:11:46.430
 završiti izazov se vidi kao 

00:11:44.510 --> 00:11:48.260
 prvi korak ka stvaranju AI 

00:11:46.430 --> 00:11:49.700
 može da se kreće dalje od igara za rešavanje 

00:11:48.260 --> 00:11:52.010
 problemi u stvarnom svijetu 

00:11:49.700 --> 00:11:54.740
 profesor Baldies kaže citat 

00:11:52.010 --> 00:11:57.140
 rešenje Rubikove kocke 

00:11:54.740 --> 00:11:59.330
 simbolički matematički i apstraktni 

00:11:57.140 --> 00:12:01.040
 tako duboku mašinu za učenje koja 

00:11:59.330 --> 00:12:03.500
 može da razbije takvu zagonetku 

00:12:01.040 --> 00:12:06.740
 bliže tome da postane sistem koji može 

00:12:03.500 --> 00:12:07.430
 Razmišljajte kako planirate i donosite odluke 

00:12:06.740 --> 00:12:09.950
 quote 

00:12:07.430 --> 00:12:11.120
 ovo zvuči odlično ovo je 

00:12:09.950 --> 00:12:14.870
 zanimljiva priča 

00:12:11.120 --> 00:12:17.240
 Dobijam obrazloženje da ga koristim 

00:12:14.870 --> 00:12:20.090
 naučite da rešavate Rubikovu kocku, ali 

00:12:17.240 --> 00:12:22.310
 Rubikova Kocka je riješena kao ti 

00:12:20.090 --> 00:12:23.960
 online i možete to učiniti kao da to uradite 

00:12:22.310 --> 00:12:26.840
 ovo i postoji niz koji slijedite 

00:12:23.960 --> 00:12:29.840
 kako to mogu da uradim da, koliko sekundi 

00:12:26.840 --> 00:12:31.970
 za ovu mašinu, tačno ne 

00:12:29.840 --> 00:12:34.910
 ali to je tako interesantno 

00:12:31.970 --> 00:12:38.240
 interesantan da život pronalazi način na koji je 

00:12:34.910 --> 00:12:39.560
 zanimljiv način kako su to učinili 

00:12:38.240 --> 00:12:43.930
 koristio sam ga, ali u isto vreme idem 

00:12:39.560 --> 00:12:47.740
 izaberi nešto što nije rešeno 

00:12:43.930 --> 00:12:47.740
 izgovor nedostaje poenta 

00:12:48.010 --> 00:12:53.990
 oni moraju dokazati koliko brzo to može riješiti 

00:12:51.620 --> 00:12:56.030
 neke stvari testiranjem protiv 

00:12:53.990 --> 00:12:57.710
 ali i kako se rešava 

00:12:56.030 --> 00:13:00.290
 da me pitate samo apstraktno pitanje 

00:12:57.710 --> 00:13:02.810
 pitaj me bilo šta 

00:13:00.290 --> 00:13:05.090
 potpuno van tamo koliko 

00:13:02.810 --> 00:13:07.520
 čestice goriva dobijate iza sebe 

00:13:05.090 --> 00:13:11.600
 Jet stream vidim da ne znam odgovor 

00:13:07.520 --> 00:13:13.190
 na to nemam pojma i mogu da odgovorim 

00:13:11.600 --> 00:13:14.630
 da si me to pitao 

00:13:13.190 --> 00:13:17.690
 da mogu ostaviti svoj odgovor 

00:13:14.630 --> 00:13:18.529
 to bilo kakvo pitanje, ali činjenica je ovde 

00:13:17.690 --> 00:13:19.850
 To je u redu 

00:13:18.529 --> 00:13:21.589
 Sjedio sam s Rubikovom kockom 

00:13:19.850 --> 00:13:24.889
 Da, u kolibi jer te poznaješ 

00:13:21.589 --> 00:13:27.079
 dobio sam zabavu i bio je lijen i i 

00:13:24.889 --> 00:13:27.920
 ne da nije bilo lenjosti 

00:13:27.079 --> 00:13:29.930
 o Rubikovoj kocki 

00:13:27.920 --> 00:13:31.550
 Ja sam inteligentan momak iako je to 

00:13:29.930 --> 00:13:33.980
 dobro je za stimulaciju mozga i 

00:13:31.550 --> 00:13:35.930
 Ja sam inteligentan, ali ne mislim 

00:13:33.980 --> 00:13:37.279
 Nikada nisam to rešio, mislim da nisam 

00:13:35.930 --> 00:13:39.470
 Došao sam do tačke gde sam samo 

00:13:37.279 --> 00:13:42.379
 frustriran sam dobio kao dvije strane i ja sam 

00:13:39.470 --> 00:13:45.649
 kao što zaboravi ovo, zapravo povlačim 

00:13:42.379 --> 00:13:46.639
 komadi se kao dijete sam addy naljepnica umočiti 

00:13:45.649 --> 00:13:49.370
 i pročita ga 

00:13:46.639 --> 00:13:52.029
 zato razmislite o tome da je dobro, pa sam odustao 

00:13:49.370 --> 00:13:54.860
 kao čovek, sada je ovo kompjuter 

00:13:52.029 --> 00:13:57.079
 algoritam koji koristi AI tehnologiju a 

00:13:54.860 --> 00:14:00.290
 neuralne mreže, tako najbliže a 

00:13:57.079 --> 00:14:01.790
 Neuralna mreža koju smo u osnovi videli 

00:14:00.290 --> 00:14:03.920
 kao da stvarno počinjemo da ih vidimo 

00:14:01.790 --> 00:14:07.720
 stvari tako mislim kao poručnik 

00:14:03.920 --> 00:14:10.579
 podaci počinju da razmišljaju sami za sebe 

00:14:07.720 --> 00:14:13.279
 evo izazova pa sam rekao 

00:14:10.579 --> 00:14:15.499
 ovaj kompjuter je izazov 

00:14:13.279 --> 00:14:17.180
 potrebno je da boje odgovaraju samo da 

00:14:15.499 --> 00:14:19.069
 preko SATA pada da su im rekli 

00:14:17.180 --> 00:14:21.649
 to je to to je to 

00:14:19.069 --> 00:14:24.529
 to je kraj igre i računar ima 

00:14:21.649 --> 00:14:27.740
 rekao je u redu bum boo-boom boom-boom figured 

00:14:24.529 --> 00:14:29.779
 to je da i suđenje i greška i hmm 

00:14:27.740 --> 00:14:30.410
 možda ako pokušam ovo i shvatim 

00:14:29.779 --> 00:14:33.079
 desno 

00:14:30.410 --> 00:14:34.550
 ne i kao da je to neverovatno 

00:14:33.079 --> 00:14:36.889
 Činjenica da sam to učinila za nešto više od sekunde 

00:14:34.550 --> 00:14:38.899
 kao da sam ga sredio, nema 

00:14:36.889 --> 00:14:40.399
 priča je nešto više od sekunde kao da je 

00:14:38.899 --> 00:14:42.470
 rastvarač u nešto više od sekunde koji je 

00:14:40.399 --> 00:14:44.480
 neverovatno je tako rešio, ali shvatio 

00:14:42.470 --> 00:14:46.850
 ne samo da nisu kao što su rekli 

00:14:44.480 --> 00:14:48.230
 Dobro, programirat ću ga da ga okrene 

00:14:46.850 --> 00:14:50.360
 na taj način okrenite ga na taj način 

00:14:48.230 --> 00:14:53.269
 ne, rekli su da je ovo ovo 

00:14:50.360 --> 00:14:56.569
 ono što vam je potrebno da to uradite i rešite 

00:14:53.269 --> 00:14:59.420
 kompjuter je shvatio da je neverovatno 

00:14:56.569 --> 00:15:02.929
 tehnologija koja će promijeniti svijet 

00:14:59.420 --> 00:15:04.459
 Da, naravno da je tako 

00:15:02.929 --> 00:15:08.740
 pozitivnu stranu koju kažete na ovu sličnu 

00:15:04.459 --> 00:15:12.410
 tehnologija kako možemo riješiti problem 

00:15:08.740 --> 00:15:15.949
 ekološka kriza kako možemo dobiti 

00:15:12.410 --> 00:15:19.189
 ulje izliti iz uvale desno i 

00:15:15.949 --> 00:15:20.839
 i to je to ideja 

00:15:19.189 --> 00:15:22.309
 idemo do tačke gde ćemo 

00:15:20.839 --> 00:15:24.559
 mogu postavljati takva pitanja 

00:15:22.309 --> 00:15:26.449
 AI kompjutera koji mislite da je Google brz 

00:15:24.559 --> 00:15:27.949
 mislite da je Google impresivan svojim 

00:15:26.449 --> 00:15:28.490
 rezultati dobro ovo će ti raznijeti 

00:15:27.949 --> 00:15:30.319
 um 

00:15:28.490 --> 00:15:31.980
 svakako dobro sa tom pričom 

00:15:30.319 --> 00:15:34.410
 čini me da odem 

00:15:31.980 --> 00:15:36.569
 malo je činjenica da je riješena 

00:15:34.410 --> 00:15:38.069
 to je potpuno drugačija logika 

00:15:36.569 --> 00:15:39.600
 uzorak nego način na koji ljudi 

00:15:38.069 --> 00:15:41.220
 i ako misli drugačije, to čini šta 

00:15:39.600 --> 00:15:44.910
 je divno, ali ako žele 

00:15:41.220 --> 00:15:47.549
 da im AI oponaša ljude da to dopuste 

00:15:44.910 --> 00:15:49.980
 posao da se onda uzme i ode u redu 

00:15:47.549 --> 00:15:53.399
 šta je sa ovom složenom stvari koju smo mi 

00:15:49.980 --> 00:15:55.350
 nisam uspeo da shvatim 

00:15:53.399 --> 00:15:57.419
 logična misao koja kaže da će ići 

00:15:55.350 --> 00:15:58.379
 smislite rješenje koje ne možemo 

00:15:57.419 --> 00:16:01.529
 zamotajte nam glave 

00:15:58.379 --> 00:16:04.589
 to je neizbežno pitanje kako 

00:16:01.529 --> 00:16:06.509
 da li kontrolišemo AI tako da kažem da je najveći 

00:16:04.589 --> 00:16:07.889
 pitanje sada i mislim da jeste 

00:16:06.509 --> 00:16:09.720
 čitav deo ove priče 

00:16:07.889 --> 00:16:11.819
 najviše me uzbuđuje što nije 

00:16:09.720 --> 00:16:13.350
 o Rubikovoj kocki je o tome 

00:16:11.819 --> 00:16:15.929
 je kako se misli kako se prilagođavamo 

00:16:13.350 --> 00:16:18.389
 programiranje inteligentne inteligencije da mislimo kao i mi 

00:16:15.929 --> 00:16:19.799
 kada su mogli da urade to je cela 

00:16:18.389 --> 00:16:22.139
 nijedna igra-izmjenjivač, jer onda to ide 

00:16:19.799 --> 00:16:24.449
 hej kako ćemo riješiti veliko smeće 

00:16:22.139 --> 00:16:26.009
 Patch u Tihom oceanu je dvostruko 

00:16:24.449 --> 00:16:28.619
 veličinu Teksasa, pa dobro 

00:16:26.009 --> 00:16:31.199
 ovako da, kao da postoji odgovor 

00:16:28.619 --> 00:16:33.299
 i kada je Martin Ford došao u emisiju 

00:16:31.199 --> 00:16:36.929
 govoriti o umjetnoj inteligenciji i 

00:16:33.299 --> 00:16:38.819
 i gde su sada kao kao 

00:16:36.929 --> 00:16:41.220
 autor u polju kao što je koristio 

00:16:38.819 --> 00:16:44.850
 primjere kao što mi radimo 

00:16:41.220 --> 00:16:48.569
 razumeti proces da da AI 

00:16:44.850 --> 00:16:49.860
 koristi da dođemo do rešenja koje nam je potrebno 

00:16:48.569 --> 00:16:52.529
 da razumemo da i mi moramo imati 

00:16:49.860 --> 00:16:55.470
 kontrolu, jer je to jednostavan zahtev 

00:16:52.529 --> 00:17:00.089
 AI da kažem u primjeru koji je koristio 

00:16:55.470 --> 00:17:02.220
 bio je da napravimo našu kompaniju za papir 

00:17:00.089 --> 00:17:04.529
 efikasan i onda odjednom 

00:17:02.220 --> 00:17:07.500
 AI preuzima i sa njom u okviru ne 

00:17:04.529 --> 00:17:10.620
 koliko im je vremena AI 

00:17:07.500 --> 00:17:13.230
 izvlačenje resursa sa svih strana i 

00:17:10.620 --> 00:17:15.569
 da napravimo efikasnu kompaniju za spajanje 

00:17:13.230 --> 00:17:18.419
 mesto gde je sada ljudska civilizacija 

00:17:15.569 --> 00:17:21.329
 je uništen, ali spajalice su još uvek 

00:17:18.419 --> 00:17:23.189
 proizvodimo vrlo efikasno mi 

00:17:21.329 --> 00:17:26.909
 moramo imati kontrolu koju moramo imati 

00:17:23.189 --> 00:17:31.830
 razumeti proces koji je AI 

00:17:26.909 --> 00:17:33.720
 to je pravo razmišljanje i možete dobiti 

00:17:31.830 --> 00:17:35.519
 naše glave oko onoga što je sada teško 

00:17:33.720 --> 00:17:37.740
 onu koju znate ako ne misle 

00:17:35.519 --> 00:17:38.820
 Slažem se da znamo da imamo 

00:17:37.740 --> 00:17:39.840
 Novac o sobi za ćaskanje o čemu govorimo 

00:17:38.820 --> 00:17:41.549
 ovo i hrana donosi novi 

00:17:39.840 --> 00:17:43.720
 pitanje je koliko puta je AI 

00:17:41.549 --> 00:17:45.760
 prvo riješiti zagonetku 

00:17:43.720 --> 00:17:48.549
 to bi bilo zanimljivo znati 

00:17:45.760 --> 00:17:50.740
 jednostavno oh ovo je situacija I 

00:17:48.549 --> 00:17:51.970
 moram da pokrenem neke prdeže u redu da ili je to uradio 

00:17:50.740 --> 00:17:54.429
 zapravo prolazi kroz suđenje i greške 

00:17:51.970 --> 00:17:56.530
 Zanimljivo je da znam da li bih 

00:17:54.429 --> 00:17:57.970
 zamislite kao i mi nemamo 

00:17:56.530 --> 00:17:59.830
 Odgovorite na ovo i nije u 

00:17:57.970 --> 00:18:01.870
 vesti ali zamišljam da je to 

00:17:59.830 --> 00:18:03.789
 on je to naučio i onda je mogao 

00:18:01.870 --> 00:18:06.340
 bolje ga riješiti ako to naučim ja 

00:18:03.789 --> 00:18:09.700
 nemojte misliti da je jedna sekunda uključena 

00:18:06.340 --> 00:18:11.169
 učenje i razmišljanje kako, ali 

00:18:09.700 --> 00:18:13.059
 onda kada je predstavljena 

00:18:11.169 --> 00:18:16.750
 naučiti kako se nositi s a 

00:18:13.059 --> 00:18:19.000
 Rubikova kocka kao ljudsko dete 

00:18:16.750 --> 00:18:22.150
 moglo bi se ovako i pomeriti 

00:18:19.000 --> 00:18:24.220
 na taj način treba vremena da da 

00:18:22.150 --> 00:18:25.900
 morao bi to naučiti, ali to je 

00:18:24.220 --> 00:18:31.000
 dobro pitanje, tako da ćemo pozirati 

00:18:25.900 --> 00:18:34.900
 da na ono što ću pitati Intel ima 

00:18:31.000 --> 00:18:38.080
 predstavio svoj novi AI sistem Pahokee beach 

00:18:34.900 --> 00:18:40.539
 to je moralni morfički kompjuter 

00:18:38.080 --> 00:18:43.630
 sposoban da simulira osam miliona 

00:18:40.539 --> 00:18:45.750
 neuroni neuromorfni inženjering 

00:18:43.630 --> 00:18:48.429
 poznato kao neuromorfno računanje 

00:18:45.750 --> 00:18:51.340
 opisuje upotrebu sistema koji sadrže 

00:18:48.429 --> 00:18:53.919
 elektronski analogni krugovi za oponašanje 

00:18:51.340 --> 00:18:56.440
 neurobiološka arhitektura u 

00:18:53.919 --> 00:18:58.480
 prisutan je nervni sistem 

00:18:56.440 --> 00:19:00.400
 Neuromorfno istraživanje je postići 

00:18:58.480 --> 00:19:03.640
 superkompjutera hiljadu puta više 

00:19:00.400 --> 00:19:06.190
 danas snažniji od bilo kog drugog za vreme DARPA 

00:19:03.640 --> 00:19:09.340
 samit inicijative za obnovu elektronike 

00:19:06.190 --> 00:19:11.020
 u ponedeljak u Detroitu Intel je predstavio 64 

00:19:09.340 --> 00:19:14.860
 kompjuter koji može simulirati 

00:19:11.020 --> 00:19:17.940
 osam miliona neurona u Intelu 

00:19:14.860 --> 00:19:20.919
 direktor laboratorija je rekao bogati direktor 

00:19:17.940 --> 00:19:23.710
 Pahokee Beach će biti dostupan 

00:19:20.919 --> 00:19:26.140
 šezdeset partnera u istraživanju koji su citirali avans 

00:19:23.710 --> 00:19:29.049
 polje kraj citat i povećati AI 

00:19:26.140 --> 00:19:35.169
 algoritmi kao što su rezervno kodiranje i putanja 

00:19:29.049 --> 00:19:38.230
 planiranje pokey Beach pack 64 low key 128 

00:19:35.169 --> 00:19:40.600
 jezgra 14 nanometara i neuromorfni čipovi 

00:19:38.230 --> 00:19:46.150
 koji su bili prvi detaljni u oktobru 

00:19:40.600 --> 00:19:49.659
 2017 svaki niži loi procesor ima 60 

00:19:46.150 --> 00:19:53.380
 veličine milimetra i sadrže više od dva 

00:19:49.659 --> 00:19:55.190
 milijarde tranzistora 130.000 veštačkih 

00:19:53.380 --> 00:19:57.950
 neurona i 100 

00:19:55.190 --> 00:20:00.290
 i 30 miliona sinapsi 

00:19:57.950 --> 00:20:03.320
 tri za jezerske jezgre 

00:20:00.290 --> 00:20:07.130
 orkestracija zadataka prema Intelu 

00:20:03.320 --> 00:20:09.020
 Loy obrađuje informacije do 1.000 

00:20:07.130 --> 00:20:11.810
 puta brže i 10.000 puta više 

00:20:09.020 --> 00:20:13.760
 efikasno od tradicionalnih prerađivača 

00:20:11.810 --> 00:20:15.800
 i može riješiti određene vrste 

00:20:13.760 --> 00:20:18.770
 problemi optimizacije sa više od 

00:20:15.800 --> 00:20:21.230
 Tri reda veličine dobijaju na brzini 

00:20:18.770 --> 00:20:24.140
 i energetsku efikasnost u odnosu na 

00:20:21.230 --> 00:20:26.690
 konvencionalne CPU operacije čip 

00:20:24.140 --> 00:20:29.660
 troši oko 100 puta manje energije 

00:20:26.690 --> 00:20:33.140
 nego što se široko koristi simulacija pokretanja procesora 

00:20:29.660 --> 00:20:35.240
 lokacije i metode mapiranja Intel kaže 

00:20:33.140 --> 00:20:38.810
 da će se kasnije ove godine predstaviti 

00:20:35.240 --> 00:20:42.380
 još veći lahi sistem Pahokee 

00:20:38.810 --> 00:20:44.750
 Opruge koje će vam dati citat 

00:20:42.380 --> 00:20:47.240
 bez presedana nivo performansi i 

00:20:44.750 --> 00:20:52.910
 efikasnost za neuromorfna radna opterećenja 

00:20:47.240 --> 00:20:54.410
 sa više od 100 miliona neurona, ali 

00:20:52.910 --> 00:20:57.200
 nisu pokrili šta se kikotalo 

00:20:54.410 --> 00:20:59.210
 da li je tri boda jedan se sjećaš 

00:20:57.200 --> 00:21:04.850
 kada su procesori zaista bili prijateljski raspoloženi 

00:20:59.210 --> 00:21:08.680
 imena kao što je Pentium Celeron tako dobro 

00:21:04.850 --> 00:21:12.590
 sve je kao strana riječ 

00:21:08.680 --> 00:21:15.500
 stvarno je teško, ali ti dobijaš suštinu 

00:21:12.590 --> 00:21:19.580
 od toga - kada možemo dodati naš kripto 

00:21:15.500 --> 00:21:23.780
 rudari na ovo da i da mislim 

00:21:19.580 --> 00:21:24.980
 treće pitanje je kao i nije 

00:21:23.780 --> 00:21:27.290
 zaista pitanje, ali više o 

00:21:24.980 --> 00:21:30.280
 izjave koje vide kako tehnologija ima 

00:21:27.290 --> 00:21:33.860
 napredovao i saslušao to sada 

00:21:30.280 --> 00:21:39.470
 procesori su opisani u terminima 

00:21:33.860 --> 00:21:42.890
 ovakvih neurona i pozitrona 

00:21:39.470 --> 00:21:47.330
 Stvari iz Star Treka su kao da smo mi 

00:21:42.890 --> 00:21:54.610
 Govoreći o mozgu ovo je mozak u 8 sati 

00:21:47.330 --> 00:22:00.650
 miliona koliko je osam miliona neurona 

00:21:54.610 --> 00:22:03.230
 tako da mi mislimo da je to milijarda a 

00:22:00.650 --> 00:22:06.800
 bolji mozak nego što nemamo ne oh, Bože 

00:22:03.230 --> 00:22:08.900
 ne, brže ne znam 

00:22:06.800 --> 00:22:11.510
 Da, ovo nije ništa u poređenju 

00:22:08.900 --> 00:22:15.230
 ljudski mozak, ali opet na njega 

00:22:11.510 --> 00:22:17.780
 znajući da računari počinju 

00:22:15.230 --> 00:22:20.570
 misliti da i da su sada 

00:22:17.780 --> 00:22:22.520
 oni izgrađuju mozak iz kompjutera 

00:22:20.570 --> 00:22:25.300
 čipovi sada želim da znam 

00:22:22.520 --> 00:22:27.440
 kako se to može usporediti s Watsonom Oh 

00:22:25.300 --> 00:22:31.250
 Watson ne bi bio ništa u poređenju sa ovim 

00:22:27.440 --> 00:22:34.460
 u pravu smo, pričamo kao u priči 

00:22:31.250 --> 00:22:38.540
 pričati o tome kako ovo može biti hiljadu 

00:22:34.460 --> 00:22:41.840
 to je brže nego bilo koji superkompjuter 

00:22:38.540 --> 00:22:42.980
 danas postoji upravo u našem liku kako 

00:22:41.840 --> 00:22:45.080
 mnogo je u bliskoj budućnosti 

00:22:42.980 --> 00:22:46.370
 Watsone, to je sve što ćemo 

00:22:45.080 --> 00:22:50.960
 uradi ovo i način na koji će stvarno 

00:22:46.370 --> 00:22:53.150
 biti bolji po krivici da tako opet pitati 

00:22:50.960 --> 00:22:55.700
 to pitanje kako možemo riješiti svijet 

00:22:53.150 --> 00:23:00.020
 Glad znate samo mi odgovorite 

00:22:55.700 --> 00:23:02.990
 dobro prije svega da imam nešto što imam 

00:23:00.020 --> 00:23:04.130
 neke sugestije, tako da će to biti 

00:23:02.990 --> 00:23:07.220
 Pomoći ću sa takvim stvarima 

00:23:04.130 --> 00:23:09.740
 ako je u desnoj ruci mm-hmm i 

00:23:07.220 --> 00:23:11.900
 to je samo lud kao što sam ja 

00:23:09.740 --> 00:23:14.600
 Apsolutno sam razočaran do te tačke 

00:23:11.900 --> 00:23:17.060
 vezan za jezik jer sam sve stavio 

00:23:14.600 --> 00:23:19.250
 ovako u kontekstu podataka jer 

00:23:17.060 --> 00:23:22.450
 i podatke o znaku Star Trek 

00:23:19.250 --> 00:23:25.730
 jer to je pozitronska mreža koja je 

00:23:22.450 --> 00:23:28.870
 neuromorfnog kompjutera desno i sada 

00:23:25.730 --> 00:23:31.840
 zapravo smo u redu ovo je kao točka 

00:23:28.870 --> 00:23:34.580
 ovo je rudimentarni 

00:23:31.840 --> 00:23:37.220
 uvodnu verziju mržnje koju imaju 

00:23:34.580 --> 00:23:38.870
 tehnologija AI sada tako da može da misli 

00:23:37.220 --> 00:23:40.970
 za sebe može naučiti kako riješiti problem 

00:23:38.870 --> 00:23:42.860
 Rubikova Kocka u sekundi i imamo 

00:23:40.970 --> 00:23:45.950
 Tehnologija koja će je brzo napraviti i napraviti 

00:23:42.860 --> 00:23:51.020
 da bi mogao da razmišlja veoma 

00:23:45.950 --> 00:23:53.390
 brzi način kao da radite u tehnici 

00:23:51.020 --> 00:23:55.790
 Da, i vi mnogo ne radite u a 

00:23:53.390 --> 00:23:57.560
 Sviđa mi se ove stvari kao i moje, ali ne 

00:23:55.790 --> 00:23:59.810
 obavljate mnogo servisnih poziva i slično 

00:23:57.560 --> 00:24:03.110
 ljudi obojeni mogu li zamisliti ako 

00:23:59.810 --> 00:24:05.480
 postojala je AI takmičenje kao mikro 

00:24:03.110 --> 00:24:08.900
 verziju koju je vaša kompanija kupila 

00:24:05.480 --> 00:24:11.800
 mmm koji je to dozvolio VPN-u u ljudi 

00:24:08.900 --> 00:24:13.700
 kućna računala za rješavanje njihovog problema 

00:24:11.800 --> 00:24:15.980
 automatski za njih možete zamisliti 

00:24:13.700 --> 00:24:18.290
 kako bi to promijenilo vašu industriju mmm 

00:24:15.980 --> 00:24:20.810
 u mojoj industriji ima mnogo toga 

00:24:18.290 --> 00:24:21.990
 suvišan i time mislim 

00:24:20.810 --> 00:24:24.990
 repetitive yes 

00:24:21.990 --> 00:24:26.190
 to je uvek ista stvar, ali mislim 

00:24:24.990 --> 00:24:29.100
 uzmete nešto ovako što mogu ići 

00:24:26.190 --> 00:24:31.620
 kao da da volim kako i mogu razgovarati 

00:24:29.100 --> 00:24:34.340
 znači razgovarati sa svojim Amazon echo i biti 

00:24:31.620 --> 00:24:37.410
 kao da zvuči kao osoba 

00:24:34.340 --> 00:24:39.750
 mogu da razgovaraju tako da znate 

00:24:37.410 --> 00:24:42.480
 tu su sve vrste zlokobnih stvari 

00:24:39.750 --> 00:24:44.520
 ali ako u desnim rukama to može biti a 

00:24:42.480 --> 00:24:47.070
 vrlo moćan alat za dobro pravo tako 

00:24:44.520 --> 00:24:49.410
 ovo je upravo otkriveno i 

00:24:47.070 --> 00:24:54.030
 razvijena ali autonomna vozila 

00:24:49.410 --> 00:24:56.700
 Već tamo desno da ne ne ne 

00:24:54.030 --> 00:25:00.720
 putem interneta vrlo Wi-Fi putem 

00:24:56.700 --> 00:25:04.800
 LTE ili 5g ili šta god želite 

00:25:00.720 --> 00:25:06.660
 kao da je uvek povezan 

00:25:04.800 --> 00:25:08.520
 sada odjednom imate ovu vrstu 

00:25:06.660 --> 00:25:11.700
 mozga koji pokreće neuronsku mrežu 

00:25:08.520 --> 00:25:13.740
 autonomnih vozila 

00:25:11.700 --> 00:25:15.210
 zapamti o tome da ću reći godinu i a 

00:25:13.740 --> 00:25:16.500
 pola svake dve godine. Ne znam 

00:25:15.210 --> 00:25:18.300
 ako postoji priča o vijestima, ali ono što mi imamo 

00:25:16.500 --> 00:25:19.530
 govorio je o tonu vozila i ja 

00:25:18.300 --> 00:25:21.570
 rekao je da ne bi bilo neverovatno ako možemo 

00:25:19.530 --> 00:25:25.020
 doći do mjesta gdje je promet 

00:25:21.570 --> 00:25:27.270
 upravljanje preko povezanih automobila 

00:25:25.020 --> 00:25:29.429
 trenutno na osnovu toga 

00:25:27.270 --> 00:25:30.480
 ljudi voze obrasce njihovog rada 

00:25:29.429 --> 00:25:32.010
 hours yeah 

00:25:30.480 --> 00:25:33.270
 čitajući njihov raspored i sada smo 

00:25:32.010 --> 00:25:34.860
 u privatnost i sve vrste stvari 

00:25:33.270 --> 00:25:36.120
 ali sigurno znate da znate čitanje 

00:25:34.860 --> 00:25:38.040
 Vaš Google Conner gdje biste trebali 

00:25:36.120 --> 00:25:40.140
 vozi vreme da odeš moraš da ga ostaviš 

00:25:38.040 --> 00:25:41.610
 ovaj put usput uzmite taj izlaz 

00:25:40.140 --> 00:25:44.460
 izlaz i negde kompjuter 

00:25:41.610 --> 00:25:46.620
 to je rutiranje svih ovih autonomnih automobila 

00:25:44.460 --> 00:25:48.570
 to je kao da si samo otišao. Dobro sam 

00:25:46.620 --> 00:25:51.179
 i prave leteće taksije 

00:25:48.570 --> 00:25:55.320
 da i dodajte to u miks 

00:25:51.179 --> 00:25:58.770
 nemaš razloga da kasniš 

00:25:55.320 --> 00:26:01.800
 kompjuter napravljen na vreme koji je neverovatan 

00:25:58.770 --> 00:26:03.929
 hajde da pogledamo brzo 

00:26:01.800 --> 00:26:06.630
 Tržište kripto valute je to kako to čini 

00:26:03.929 --> 00:26:09.540
 izgleda ovde 2019. pre neuralnog 

00:26:06.630 --> 00:26:12.030
 mreža nam dozvoljava da masovno masiramo 

00:26:09.540 --> 00:26:15.179
 količine Bitcoin-a tako sada 

00:26:12.030 --> 00:26:17.220
 Bitcoin sjedi na 9700 devedeset dva 

00:26:15.179 --> 00:26:20.220
 dolara i 67 centi 

00:26:17.220 --> 00:26:24.120
 sve se gubi Bitcoin Bitcoin gubljenje 

00:26:20.220 --> 00:26:27.420
 iako je to najveći gubitnik 2137 

00:26:24.120 --> 00:26:30.540
 dolara i 35 centi u poslednjem 

00:26:27.420 --> 00:26:31.980
 tjedan Facebook Libre još uvijek sjedi na 

00:26:30.540 --> 00:26:33.570
 Nula dolara i ja ću zadržati 

00:26:31.980 --> 00:26:35.200
 da vam to kažem, jer jednog dana je 

00:26:33.570 --> 00:26:36.789
 će biti vredan peni 

00:26:35.200 --> 00:26:38.919
 i onda to znamo 

00:26:36.789 --> 00:26:41.019
 Facebook zapravo radi ono što oni 

00:26:38.919 --> 00:26:42.549
 rekao je da će uraditi litecoin 

00:26:41.019 --> 00:26:46.510
 devedeset jedan dolar i tri centa niže 

00:26:42.549 --> 00:26:47.980
 šesnaest i 72 centa u dva sata 

00:26:46.510 --> 00:26:50.919
 sto i trinaest dolara i 72 

00:26:47.980 --> 00:26:53.769
 centi na sedamdeset i sedam pedeset devet 

00:26:50.919 --> 00:26:56.440
 sada je obrtni momenat nula tačke devet šest deset 

00:26:53.769 --> 00:26:59.169
 hiljaditi deo centa i novčić za kornjače 

00:26:56.440 --> 00:27:00.669
 takođe gubi na nuli od devet do osam deset 

00:26:59.169 --> 00:27:01.809
 hiljaditi deo centa pamti ako 

00:27:00.669 --> 00:27:04.600
 ići ćeš na moje ako hoćeš 

00:27:01.809 --> 00:27:06.909
 investirati ili na drugi način raditi 

00:27:04.600 --> 00:27:09.250
 cryptocurrency je tržište koje nikada 

00:27:06.909 --> 00:27:11.919
 zatvara i to je tržište koje je uvijek 

00:27:09.250 --> 00:27:15.510
 volatile pa budite oprezni i samo trošite 

00:27:11.919 --> 00:27:18.460
 investirati samo tamo gdje si možete priuštiti da izgubite 

00:27:15.510 --> 00:27:19.990
 veliko hvala Roy W Nashu i našem 

00:27:18.460 --> 00:27:21.880
 zajednica gledalaca za podnošenje 

00:27:19.990 --> 00:27:23.950
 priče za nas ove nedelje hvala 

00:27:21.880 --> 00:27:25.960
 gledajući TV redak kategorije pet 

00:27:23.950 --> 00:27:27.909
 nemojte zaboraviti da volite i pretplatite se 

00:27:25.960 --> 00:27:29.769
 sve vaše tehnološke novosti sa malim Linuxom 

00:27:27.909 --> 00:27:31.510
 pristranost i više slobodnog sadržaja 

00:27:29.769 --> 00:27:33.730
 da proverite našu web stranicu iz 

00:27:31.510 --> 00:27:35.860
 TV-red za kategoriju pet sam Saša 

00:27:33.730 --> 00:27:38.309
 Rickman i ja smo Robbie Ferguson i ja sam 

00:27:35.860 --> 00:27:38.309
 Jeff Lester 

00:27:42.860 --> 00:27:48.640
 [Muzika] 

00:27:46.560 --> 00:27:58.640
 [Aplauz] 

00:27:48.640 --> 00:27:58.640
 [Muzika] 

