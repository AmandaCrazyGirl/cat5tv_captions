WEBVTT
Kind: captions
Language: hu

00:00:00.030 --> 00:00:05.009
 itt vannak a történetek, amelyek ezt lefedik 

00:00:01.949 --> 00:00:06.960
 hét az 5. kategóriás TV hírcsarnokban 

00:00:05.009 --> 00:00:08.880
 úgy döntött, hogy a Facebookot büntetik a 

00:00:06.960 --> 00:00:11.460
 öt milliárd dollárt dobott a 

00:00:08.880 --> 00:00:14.040
 Cambridge analitikus botránya teljesen 

00:00:11.460 --> 00:00:17.060
 interaktív a Doctor Who VR játék a 

00:00:14.040 --> 00:00:19.439
 szeptemberben érkezik az idő széle 

00:00:17.060 --> 00:00:21.420
 létrehozott mesterséges intelligencia rendszer 

00:00:19.439 --> 00:00:23.670
 a. \ t 

00:00:21.420 --> 00:00:27.300
 Kalifornia megoldotta a Rubik-kockát 

00:00:23.670 --> 00:00:30.779
 alig több mint egy másodperc alatt és az Intel 

00:00:27.300 --> 00:00:33.960
 bemutatta új AI rendszerét, Hawaii Beachet 

00:00:30.779 --> 00:00:36.809
 ez egy neuromorf számítógép, amely képes 

00:00:33.960 --> 00:00:38.280
 nyolc millió idegsejtet szimulál 

00:00:36.809 --> 00:00:41.280
 jönnek a történetek 

00:00:38.280 --> 00:00:44.340
 ne menj sehová, ez a kategória 5 

00:00:41.280 --> 00:00:50.640
 A hét legjobb technikáját lefedő tv-hírcsarnok 

00:00:44.340 --> 00:00:52.680
 történetek egy linux, amit én sasha vagyok 

00:00:50.640 --> 00:00:54.809
 Rickman és elolvasta a legjobb történeteket 

00:00:52.680 --> 00:00:56.489
 ezen a héten ezt követően döntött 

00:00:54.809 --> 00:00:57.870
 A Facebookot egy lenyűgöző 5-ös bírság terheli 

00:00:56.489 --> 00:01:00.059
 milliárd dollárt a Cambridge-be 

00:00:57.870 --> 00:01:02.370
 analitikus botrány a fogyasztó számára 

00:01:00.059 --> 00:01:05.010
 Védelmi Ügynökség az Egyesült Államokban, a Szövetségi 

00:01:02.370 --> 00:01:07.320
 Az FTC Kereskedelmi Bizottsága vizsgálatot kezdett 

00:01:05.010 --> 00:01:09.479
 Facebook március 2018-ban 

00:01:07.320 --> 00:01:11.970
 beszámol arról, hogy Cambridge analitikus ah volt 

00:01:09.479 --> 00:01:14.549
 elérte a több tízmillió adatát 

00:01:11.970 --> 00:01:16.759
 a felhasználók, mivel kiderül, hogy a 

00:01:14.549 --> 00:01:20.100
 politikai tanácsadó cég képes volt 

00:01:16.759 --> 00:01:23.580
 helytelenül kapja meg a legfeljebb 87 adatot 

00:01:20.100 --> 00:01:26.070
 millió Facebook felhasználó a vizsgálatot 

00:01:23.580 --> 00:01:28.619
 arra összpontosított, hogy a Facebook megsértette-e 

00:01:26.070 --> 00:01:30.990
 egy 2011-es megállapodás, amelyben volt 

00:01:28.619 --> 00:01:34.170
 egyértelműen értesíteni kell a felhasználókat és 

00:01:30.990 --> 00:01:37.170
 kifejezett beleegyezésüket az adatok megosztásához 

00:01:34.170 --> 00:01:39.030
 három-két szavazásban a rekord 5 

00:01:37.170 --> 00:01:41.939
 milliárd dolláros elszámolásra került sor 

00:01:39.030 --> 00:01:43.680
 az FTC által a bírságnak még meg kell lennie 

00:01:41.939 --> 00:01:45.930
 az Igazságügyi Minisztérium véglegesítette 

00:01:43.680 --> 00:01:49.290
 Polgári Osztály, és nem világos, hogyan 

00:01:45.930 --> 00:01:51.420
 sokáig ez megtörténhet, ha megerősítené 

00:01:49.290 --> 00:01:54.540
 az a legnagyobb bírság, amelyet a. \ t 

00:01:51.420 --> 00:01:56.969
 Az FTC egy Facebook vállalatnál volt 

00:01:54.540 --> 00:01:59.280
 ezt várta, hogy a befektetők visszajöttek 

00:01:56.969 --> 00:02:01.469
 Áprilisban félretette a legtöbbet 

00:01:59.280 --> 00:02:04.170
 ez azt jelenti, hogy a cég nem fog 

00:02:01.469 --> 00:02:07.259
 úgy érzi, sokkal több pénzügyi terhelést jelent 

00:02:04.170 --> 00:02:09.629
 ez a büntetés, amit még nem tudunk 

00:02:07.259 --> 00:02:12.180
 milyen további intézkedéseket lehet tenni 

00:02:09.629 --> 00:02:13.410
 például a megnövekedett magánélet 

00:02:12.180 --> 00:02:14.640
 felügyelet vagy 

00:02:13.410 --> 00:02:16.500
 ha bármilyen személyes lesz 

00:02:14.640 --> 00:02:19.260
 a vállalat vezetője számára 

00:02:16.500 --> 00:02:21.630
 végrehajtó Mark Zuckerberg a település 

00:02:19.260 --> 00:02:23.730
 ami körülbelül egynegyedét teszi ki 

00:02:21.630 --> 00:02:25.710
 a vállalat éves nyeresége 

00:02:23.730 --> 00:02:27.450
 kritizálják azokat, akik azt mondják 

00:02:25.710 --> 00:02:29.270
 hogy a bírság nem sokkal több, mint a 

00:02:27.450 --> 00:02:33.180
 pofon a csuklóján 

00:02:29.270 --> 00:02:37.550
 hmm öt milliárd dollár nem pofon 

00:02:33.180 --> 00:02:40.110
 a csuklón egy kicsit nagyobbnak érzi magát 

00:02:37.550 --> 00:02:44.250
 2,00 $ egy nagyszerű 

00:02:40.110 --> 00:02:46.410
 igen, nem hiszem, hogy nem hiszem 

00:02:44.250 --> 00:02:49.740
 hogy figyelmen kívül hagyják a bírságot 

00:02:46.410 --> 00:02:51.570
 igaz, de továbbra is ők tették 

00:02:49.740 --> 00:02:54.990
 a legtöbb pénzt el tudjuk érni 

00:02:51.570 --> 00:02:58.380
 nem mondom, hogy hozzáférhessen a legtöbb Oh pénzhez 

00:02:54.990 --> 00:03:02.160
 ez a mi többletjogunkból 

00:02:58.380 --> 00:03:03.900
 hogy tönkre tegyük, túl túllépsz 

00:03:02.160 --> 00:03:06.650
 őszintén szólva azt hiszem, ez egy pofon volt 

00:03:03.900 --> 00:03:09.300
 csukló és én olvastam egy cikket 

00:03:06.650 --> 00:03:11.190
 a részvények után ugrott a részvény 

00:03:09.300 --> 00:03:14.310
 finom volt, hogy mm-hmm volt, miért nem 

00:03:11.190 --> 00:03:15.540
 nyom, de csaknem a részvények ugrása 

00:03:14.310 --> 00:03:20.550
 ugyanannyi pénzt hoz létre, mint amennyit 

00:03:15.540 --> 00:03:22.500
 Wow emberek szerelmesek 

00:03:20.550 --> 00:03:24.060
 olyan, mint Oh Papa véres 

00:03:22.500 --> 00:03:25.970
 Facebook ó, most visszatértük a pénzt 

00:03:24.060 --> 00:03:28.380
 mint Timmy, ez hülye 

00:03:25.970 --> 00:03:30.420
 olyan jogi szempontból, mint mi 

00:03:28.380 --> 00:03:32.280
 elvégezték, hogy te vagy 

00:03:30.420 --> 00:03:34.050
 mondván, hogy nem tettek semmit 

00:03:32.280 --> 00:03:36.060
 gyakorlatilag pontosan mit fognak tenni 

00:03:34.050 --> 00:03:39.959
 ez az öt milliárd dollár fog menni 

00:03:36.060 --> 00:03:42.709
 a szövetségi pénztárba hmm, amit akarok 

00:03:39.959 --> 00:03:46.680
 tudni, hogy ez meg fog-e állni 

00:03:42.709 --> 00:03:48.810
 olyanok, mintha valaki azt mondaná, hogy én vagyok 

00:03:46.680 --> 00:03:50.880
 most beperelte a Facebookot, amit találtál 

00:03:48.810 --> 00:03:52.680
 illúziónak kell lennie az áldozatoknak 

00:03:50.880 --> 00:03:54.810
 áldozat volt, és az életemet befolyásolta 

00:03:52.680 --> 00:03:57.530
 mert most látom ezeket a hirdetéseket 

00:03:54.810 --> 00:04:01.080
 hogy soha nem akartam látni, mielőtt akarok 

00:03:57.530 --> 00:04:02.550
 tízmillió dollár, de azt értem 

00:04:01.080 --> 00:04:05.610
 láss egy osztály-akcióruhát, ami jön ki 

00:04:02.550 --> 00:04:09.660
 ez a hmm azt jelenti, hogy ez is feláll 

00:04:05.610 --> 00:04:11.790
 valószínűleg nem csak II 

00:04:09.660 --> 00:04:14.400
 őszintén szólva minden pénzzel 

00:04:11.790 --> 00:04:16.470
 A Facebook teszi az összes behatolót 

00:04:14.400 --> 00:04:17.940
 természetüket építették 

00:04:16.470 --> 00:04:20.250
 Körülbelül öt millió vagy 

00:04:17.940 --> 00:04:22.289
 ötmillió vicc, mit akarsz 

00:04:20.250 --> 00:04:24.860
 azt állítottam volna, hogy körbejárnám 

00:04:22.289 --> 00:04:24.860
 tizenöt 

00:04:24.900 --> 00:04:31.870
 Nem harcolnék a 15.000.000.000 dollárt 

00:04:28.599 --> 00:04:34.870
 igen túl sok, de a másik dolog az én 

00:04:31.870 --> 00:04:36.039
 szerintem ez egy olyan település, amit nem gondolok 

00:04:34.870 --> 00:04:37.539
 egyenesen finom volt, azt hiszem 

00:04:36.039 --> 00:04:42.490
 vágjon egy hátsó terem üzletet, hogy tudták, mi 

00:04:37.539 --> 00:04:44.319
 jött ez egy pozitív 1/4 

00:04:42.490 --> 00:04:47.050
 az éves nyereségből, ha ki kellene töltenem 

00:04:44.319 --> 00:04:50.680
 egynegyed pénzbírságomból 

00:04:47.050 --> 00:04:57.400
 Én eszem mr-t. tészta azt hiszem 

00:04:50.680 --> 00:05:00.550
 más adócsoportban vagyunk 

00:04:57.400 --> 00:05:03.219
 gondolj rá, hogy a bírság 1/4-a 

00:05:00.550 --> 00:05:06.030
 éves bevétele kizárólag az Ön eladásából származik 

00:05:03.219 --> 00:05:09.940
 személyes adatok, amit csinálnak 

00:05:06.030 --> 00:05:12.340
 igen, én megvédem a Facebook-ot, emlékszem 

00:05:09.940 --> 00:05:15.280
 Még a Facebook-on sem vagyok 

00:05:12.340 --> 00:05:17.110
 milyen szomorú voltam mindezt 

00:05:15.280 --> 00:05:19.389
 a magánélet megsértése igen, és nem hiszem 

00:05:17.110 --> 00:05:21.909
 Zuckerberg az ablakon kívül van 

00:05:19.389 --> 00:05:25.000
 meg fogod érni, nem fogok mondani, mit 

00:05:21.909 --> 00:05:26.500
 mint a felhasználó mint programozó az egészet 

00:05:25.000 --> 00:05:29.770
 Cambridge analitikus dolog, mit csinál 

00:05:26.500 --> 00:05:31.060
 nekem szigorúan frusztráció 

00:05:29.770 --> 00:05:33.159
 az a pont, ahol minden töröltem 

00:05:31.060 --> 00:05:37.779
 Facebook szolgáltatásai a cégemen belül 

00:05:33.159 --> 00:05:39.580
 jobb, mint én már nem nyújtom a Facebook-ot 

00:05:37.779 --> 00:05:41.409
 ügyfeleinknek nyújtott szolgáltatásokat valakivel 

00:05:39.580 --> 00:05:42.789
 még üzenetet is küldött nekem, kérve, hogy hozzanak létre egy 

00:05:41.409 --> 00:05:44.949
 Instagram-profil és azt mondtam, hogy megyek 

00:05:42.789 --> 00:05:46.479
 máshol nem fogom csinálni, nem vagyok 

00:05:44.949 --> 00:05:48.909
 Nem foglalkozom ezzel a társasággal 

00:05:46.479 --> 00:05:50.289
 többé itt itt van a dolog, ami 

00:05:48.909 --> 00:05:51.460
 zavar engem egy kicsit a történetről 

00:05:50.289 --> 00:05:54.580
 és tudom, hogy tovább kell lépnünk a számra 

00:05:51.460 --> 00:05:57.099
 egy pillantást vet, amikor Elon Musk készítette 

00:05:54.580 --> 00:05:59.440
 tweet arról, hogy egy kicsit foglalkozol a tengerentúlon 

00:05:57.099 --> 00:06:01.180
 vagy valami, ami soha nem jött el, és 

00:05:59.440 --> 00:06:03.819
 hirtelen a kereskedésekből 

00:06:01.180 --> 00:06:05.349
 A Bizottságnak volt egy év szankciója 

00:06:03.819 --> 00:06:07.449
 Twitter és valaki olyan volt, mint egy 

00:06:05.349 --> 00:06:09.370
 az etikus személy követi őt, és igen 

00:06:07.449 --> 00:06:11.319
 mintha ügyvéd lett volna 

00:06:09.370 --> 00:06:13.599
 úgyhogy így volt ez a nagy üzlet mm-hmm 

00:06:11.319 --> 00:06:14.979
 mivel a Facebook milliókat bocsát ki 

00:06:13.599 --> 00:06:16.210
 az emberek személyes adatai és azok 

00:06:14.979 --> 00:06:19.960
 menjen nekünk egy kis pénzt 

00:06:16.210 --> 00:06:21.729
 mm-hmm, mint ahol a hatás a 

00:06:19.960 --> 00:06:22.990
 cég igen, azt hiszem, van egy 

00:06:21.729 --> 00:06:25.020
 sokkal több, ami vele együtt jön 

00:06:22.990 --> 00:06:27.610
 a vállalatra gyakorolt ​​hatás 

00:06:25.020 --> 00:06:29.830
 a vállalatok azt mondják, hogy nem foglalkozom 

00:06:27.610 --> 00:06:32.560
 Facebook már, de nézd, hogy nem vásárolok 

00:06:29.830 --> 00:06:35.289
 hirdetési hely a Facebookon, most én vagyok 

00:06:32.560 --> 00:06:36.969
 van egy Facebook profilja Facebook oldal 

00:06:35.289 --> 00:06:37.650
 az 5-ös kategóriájú TV-hez, mert van egy 

00:06:36.969 --> 00:06:39.690
 sok 

00:06:37.650 --> 00:06:42.630
 és így azt akarjuk, hogy hozzáférhető legyen 

00:06:39.690 --> 00:06:44.910
 te, de személyesen nem használom, és én 

00:06:42.630 --> 00:06:46.680
 ne támogassa azt, mint ez 

00:06:44.910 --> 00:06:48.900
 úgy tűnik, hogy ezen a héten ismét felrobbant 

00:06:46.680 --> 00:06:50.310
 mm-hmm és az összes személyes adat 

00:06:48.900 --> 00:06:52.860
 abból, hogy az emberek csak nem 

00:06:50.310 --> 00:06:55.229
 az ellátás, mint a nyilvánosság, nem érdekel, de én 

00:06:52.860 --> 00:06:57.300
 észre, hogy ez egy széles szalag, amit nem 

00:06:55.229 --> 00:07:00.479
 szeretnék általánosítani, és elnézést kérek 

00:06:57.300 --> 00:07:02.820
 az általánosítás, mert lehet 

00:07:00.479 --> 00:07:04.229
 mondván, nem törődöm, hogy nagyon óvatos vagyok 

00:07:02.820 --> 00:07:05.699
 Megszakítottam a fiókomat, vagy talán én 

00:07:04.229 --> 00:07:07.620
 még egy cuz-ra sem jelentkeztem 

00:07:05.699 --> 00:07:10.740
 elfogadja az Általános Szerződési Feltételeket, de 

00:07:07.620 --> 00:07:13.169
 ez a tény olyan, mintha az a 

00:07:10.740 --> 00:07:16.350
 más korszakban, mint tíz év volt 

00:07:13.169 --> 00:07:18.870
 most már az adattípusok tolvajai 

00:07:16.350 --> 00:07:21.510
 olyanok, mint a szociális dolgok 

00:07:18.870 --> 00:07:24.150
 a média tíz évvel ezelőtt nem létezett 

00:07:21.510 --> 00:07:27.210
 a törvénynek meg kell felzárkóznunk 

00:07:24.150 --> 00:07:29.130
 olyan sok más lehet, amit tudnánk 

00:07:27.210 --> 00:07:32.070
 beszéljünk MP-ről, hogy beszélhessünk 

00:07:29.130 --> 00:07:36.210
 ó, igen, mint mindezek, és 

00:07:32.070 --> 00:07:39.300
 és még nem találkoztak, és talán 

00:07:36.210 --> 00:07:40.650
 talán legalább egy lépés talán ez 

00:07:39.300 --> 00:07:42.510
 nem a Facebookról, talán nem megy 

00:07:40.650 --> 00:07:45.210
 hogy megölje őket, de talán ez lesz 

00:07:42.510 --> 00:07:47.310
 megvédeni a felhasználókat a következő nagy meghibásodástól 

00:07:45.210 --> 00:07:50.099
 mert a következő nagy H még mindig a 

00:07:47.310 --> 00:07:51.710
 remélhetőleg nem igazán tudjuk 

00:07:50.099 --> 00:07:55.260
 nagy kép 

00:07:51.710 --> 00:07:57.210
 a teljesen interaktív orvos, aki VR játékot játszik 

00:07:55.260 --> 00:07:59.820
 az idő széle érkezik 

00:07:57.210 --> 00:08:01.560
 Szeptemberben az orvos megrándult 

00:07:59.820 --> 00:08:03.780
 a világegyetem végéig 

00:08:01.560 --> 00:08:05.930
 egy vírus, amely azzal fenyeget, hogy szétszakad 

00:08:03.780 --> 00:08:08.669
 maga a valóság szabadul fel 

00:08:05.930 --> 00:08:10.440
 a játékosok a TARDIS-t a 

00:08:08.669 --> 00:08:12.630
 utazás a világon mindkettő ismerős 

00:08:10.440 --> 00:08:15.030
 és furcsa, hogy helyreállítson egy sorozatot 

00:08:12.630 --> 00:08:17.130
 erőteljes időkristályok, amelyek javíthatók 

00:08:15.030 --> 00:08:19.979
 hely-idő és végül mentse a 

00:08:17.130 --> 00:08:23.190
 maga az univerzum a közelmúlt után 

00:08:19.979 --> 00:08:25.680
 az animált VR élmény felfedése 

00:08:23.190 --> 00:08:28.260
 Doktor Ki az a újszülött film 

00:08:25.680 --> 00:08:29.729
 teljes hosszúságú Doctor Who VR videojáték 

00:08:28.260 --> 00:08:32.250
 szeptemberben jön 

00:08:29.729 --> 00:08:34.589
 által közzétett és által fejlesztett 

00:08:32.250 --> 00:08:37.320
 labirintuselmélet Doktor Ki 

00:08:34.589 --> 00:08:39.900
 az idő a rajongókat globálisan szállítja 

00:08:37.320 --> 00:08:41.969
 az idegenek szeretett világa rejtély és 

00:08:39.900 --> 00:08:44.010
 Csoda, hogy hagyja őket a 

00:08:41.969 --> 00:08:46.470
 teljesen új és teljesen interaktív 

00:08:44.010 --> 00:08:49.589
 a show 55 éves múltja 

00:08:46.470 --> 00:08:51.490
 történelem és az orvosok főszereplője 

00:08:49.589 --> 00:08:55.210
 Jody által játszott inkarnáció 

00:08:51.490 --> 00:08:57.630
 Whitaker az ikonikus hangzású 

00:08:55.210 --> 00:08:59.920
 csavarhúzó terv játékosok megoldani 

00:08:57.630 --> 00:09:01.990
 elme-hajlító rejtvények megragadnak 

00:08:59.920 --> 00:09:04.570
 klasszikus szörnyek és új találkozások 

00:09:01.990 --> 00:09:06.670
 látókörök az orvos megtalálására 

00:09:04.570 --> 00:09:08.680
 és legyőzze a hatalmas erőt 

00:09:06.670 --> 00:09:11.640
 azzal fenyeget, hogy elpusztítja a szövetet 

00:09:08.680 --> 00:09:15.640
 a valóságot a hírhedtekkel fogják szembenézni 

00:09:11.640 --> 00:09:19.180
 Daleks felix Daleks igen Dalek van 

00:09:15.640 --> 00:09:21.850
 az egyik itt a készleten vagy egy ismert 

00:09:19.180 --> 00:09:24.610
 arcok az orvosok univerzum pluszjából 

00:09:21.850 --> 00:09:26.620
 valami új, még soha nem látott 

00:09:24.610 --> 00:09:29.080
 szörnyek, amikor lenyűgözően utaznak 

00:09:26.620 --> 00:09:33.240
 mozi környezetet hoz létre 

00:09:29.080 --> 00:09:39.150
 az előadás rendben van, mindenekelőtt 

00:09:33.240 --> 00:09:39.150
 ez egy dollár, mintha igen, várok 

00:09:39.330 --> 00:09:43.900
 megsemmisíti a színészet, így a gyerekeim 

00:09:42.640 --> 00:09:45.970
 izgatott leszek erről 

00:09:43.900 --> 00:09:48.640
 Először is izgatott ez 

00:09:45.970 --> 00:09:52.270
 a történet úgy hangzik, mint a mindennapi életem 

00:09:48.640 --> 00:09:53.980
 ez nagyon szépnek hangzik ezekben a napokban 

00:09:52.270 --> 00:09:55.840
 annyit tudnak tenni, és a Jodie-t 

00:09:53.980 --> 00:09:57.550
 Whittaker valójában részt vesz a 

00:09:55.840 --> 00:10:00.070
 a tényleges játék nagyon szórakoztató lesz 

00:09:57.550 --> 00:10:03.250
 a Jodie Whittaker rajongók számára, és írja be a 

00:10:00.070 --> 00:10:06.060
 tizenegyedik orvos rajongó is, így ez 

00:10:03.250 --> 00:10:08.230
 nagyszerű igen, és megvan az Orville is 

00:10:06.060 --> 00:10:10.990
 interaktív rajongói tapasztalat 

00:10:08.230 --> 00:10:13.330
 jön a gőzbe a következő párban 

00:10:10.990 --> 00:10:15.520
 olyan hetek, mint a közeljövőben 

00:10:13.330 --> 00:10:18.040
 már a Steam-on van, így keresheted a 

00:10:15.520 --> 00:10:20.500
 Orville úgy néz ki, mint néhány 

00:10:18.040 --> 00:10:23.950
 a nagy sci-fi bemutatók most 

00:10:20.500 --> 00:10:26.500
 lesz játszható VR játékok igen 

00:10:23.950 --> 00:10:29.110
 hűvös ez nagyon jó, így várom 

00:10:26.500 --> 00:10:32.470
 erre - Köszönöm Sasha nem vagy 

00:10:29.110 --> 00:10:34.600
 VR mesterséges intelligencia rendszer 

00:10:32.470 --> 00:10:37.000
 az egyetem kutatói 

00:10:34.600 --> 00:10:40.960
 Kaliforniában megoldódott a Rubik 

00:10:37.000 --> 00:10:43.990
 Kocka a második mély kockában egy 

00:10:40.960 --> 00:10:46.150
 az algoritmus úgynevezett befejezett a 3d 

00:10:43.990 --> 00:10:49.620
 logikai puzzle, amely adóztat 

00:10:46.150 --> 00:10:52.450
 az 1974-es feltalálást követően 

00:10:49.620 --> 00:10:54.640
 professzor Pierre Baldy, aki a szerzőt írta 

00:10:52.450 --> 00:10:58.240
 jelentés a természet gépi intelligenciában 

00:10:54.640 --> 00:11:00.550
 azt mondta, hogy az idézet önállóan megtanulta 

00:10:58.240 --> 00:11:01.960
 a kutatók megjegyezték, hogy a stratégiája 

00:11:00.550 --> 00:11:04.790
 nagyon különbözik az embertől 

00:11:01.960 --> 00:11:08.210
 Baldy rejtélyprofesszorral foglalkozott 

00:11:04.790 --> 00:11:09.890
 azt mondja, hogy a legjobban kitalálom, hogy az a forma 

00:11:08.210 --> 00:11:13.070
 az érvelés teljesen más 

00:11:09.890 --> 00:11:15.350
 egy embertől a számítógépet 

00:11:13.070 --> 00:11:17.330
 az algoritmus nem az első vagy a 

00:11:15.350 --> 00:11:19.910
 a leggyorsabb nem ember, aki megoldja a puzzle-t 

00:11:17.330 --> 00:11:21.590
 ez a megtiszteltetés egy olyan rendszerre irányul, 

00:11:19.910 --> 00:11:24.650
 a Massachusetts Intézet 

00:11:21.590 --> 00:11:27.350
 A technológia a min kétfázisú 

00:11:24.650 --> 00:11:30.860
 algoritmus, amely megoldotta a három puzzle-t 

00:11:27.350 --> 00:11:32.990
 gyorsabban, de a rendszer nem használta 

00:11:30.860 --> 00:11:35.450
 egy neurális hálózat, amely utánozza, hogyan 

00:11:32.990 --> 00:11:37.700
 az emberi agy működik vagy gépi tanulás 

00:11:35.450 --> 00:11:39.850
 ellentétben a programozást 

00:11:37.700 --> 00:11:42.410
 kifejezetten a puzzle megoldására 

00:11:39.850 --> 00:11:44.510
 olyan rendszer létrehozása, amely tanítja magát 

00:11:42.410 --> 00:11:46.430
 a kihívást teljes egészében úgy kell tekinteni, mint a 

00:11:44.510 --> 00:11:48.260
 első lépés az AI létrehozása felé 

00:11:46.430 --> 00:11:49.700
 a játékokon túl is megoldható 

00:11:48.260 --> 00:11:52.010
 valós problémák 

00:11:49.700 --> 00:11:54.740
 Baldies professzora azt mondja, idézik a 

00:11:52.010 --> 00:11:57.140
 a Rubik kocka megoldása 

00:11:54.740 --> 00:11:59.330
 szimbolikus matematikai és absztrakt 

00:11:57.140 --> 00:12:01.040
 olyan mély tanulási gépet gondolva 

00:11:59.330 --> 00:12:03.500
 megrepedhet egy ilyen puzzle 

00:12:01.040 --> 00:12:06.740
 közelebb ahhoz, hogy olyan rendszerré váljunk, amely lehet 

00:12:03.500 --> 00:12:07.430
 gondolj az ok tervére és döntéseket hozj 

00:12:06.740 --> 00:12:09.950
 idézet 

00:12:07.430 --> 00:12:11.120
 ez félelmetesnek hangzik, ez egy 

00:12:09.950 --> 00:12:14.870
 érdekes történet 

00:12:11.120 --> 00:12:17.240
 Elmagyarázom a használatát 

00:12:14.870 --> 00:12:20.090
 megtanulják megoldani egy Rubik kockaját, de a 

00:12:17.240 --> 00:12:22.310
 Rubik kocka megoldódott, mint te 

00:12:20.090 --> 00:12:23.960
 online, és ez olyan, mint ez 

00:12:22.310 --> 00:12:26.840
 ezt és egy sorozatot követsz 

00:12:23.960 --> 00:12:29.840
 hogyan tudom csinálni igen, hány másodperc 

00:12:26.840 --> 00:12:31.970
 ennek a gépnek nincs igaza 

00:12:29.840 --> 00:12:34.910
 de ez így érdekes 

00:12:31.970 --> 00:12:38.240
 érdekes yeah élet találja meg a módját 

00:12:34.910 --> 00:12:39.560
 érdekes módja annak, hogy hogyan 

00:12:38.240 --> 00:12:43.930
 használta, de ugyanakkor megyek 

00:12:39.560 --> 00:12:47.740
 válasszon valamit, ami nem megoldott 

00:12:43.930 --> 00:12:47.740
 kifogás hiányzik a pont 

00:12:48.010 --> 00:12:53.990
 bizonyítaniuk kell, hogy milyen gyorsan tud megoldani 

00:12:51.620 --> 00:12:56.030
 néhány dolgot a tesztelés ellen 

00:12:53.990 --> 00:12:57.710
 valamit, de azt is, hogyan oldja meg 

00:12:56.030 --> 00:13:00.290
 kérdezzen nekem egy absztrakt kérdést 

00:12:57.710 --> 00:13:02.810
 kérdezzen csak valamit 

00:13:00.290 --> 00:13:05.090
 teljesen odakint, hány 

00:13:02.810 --> 00:13:07.520
 a tüzelőanyag részecskék mögött egy 

00:13:05.090 --> 00:13:11.600
 jet stream lásd, hogy nem tudom a választ 

00:13:07.520 --> 00:13:13.190
 ehhez nincsenek nyomom, és tudok válaszolni 

00:13:11.600 --> 00:13:14.630
 az a gosh, akitől megkérdezhetnél 

00:13:13.190 --> 00:13:17.690
 hogy el tudtam hagyni a válaszomat 

00:13:14.630 --> 00:13:18.529
 ez minden kérdés, de a tény itt 

00:13:17.690 --> 00:13:19.850
 ez rendben van 

00:13:18.529 --> 00:13:21.589
 Leültem egy Rubik kocka yep-jével 

00:13:19.850 --> 00:13:24.889
 igen a házban, mert ismeri magát 

00:13:21.589 --> 00:13:27.079
 van egy időzítése, hogy lusta és és 

00:13:24.889 --> 00:13:27.920
 nem az, hogy bármi lusta 

00:13:27.079 --> 00:13:29.930
 egy Rubik kocájáról 

00:13:27.920 --> 00:13:31.550
 Intelligens srác vagyok, bár ó 

00:13:29.930 --> 00:13:33.980
 jó az agy és az agy stimulálása 

00:13:31.550 --> 00:13:35.930
 Intelligens srác vagyok, de nem hiszem 

00:13:33.980 --> 00:13:37.279
 Valaha megoldottam, nem hiszem 

00:13:35.930 --> 00:13:39.470
 olyan pontra jutott, ahol én vagyok 

00:13:37.279 --> 00:13:42.379
 csalódott vagyok, mint két oldal, és én vagyok 

00:13:39.470 --> 00:13:45.649
 mint felejtsd el ezt, én valójában húzom 

00:13:42.379 --> 00:13:46.639
 darabok, mint egy gyerek I addy matrica 

00:13:45.649 --> 00:13:49.370
 és olvassa el 

00:13:46.639 --> 00:13:52.029
 úgyhogy csak úgy gondolja, hogy rendben van, ezért feladtam 

00:13:49.370 --> 00:13:54.860
 mint ember, most ez egy számítógép 

00:13:52.029 --> 00:13:57.079
 AI technológiával működő algoritmus a 

00:13:54.860 --> 00:14:00.290
 úgy, hogy a legközelebbi dolog az a 

00:13:57.079 --> 00:14:01.790
 neurális háló, amit alapvetően láttunk 

00:14:00.290 --> 00:14:03.920
 mintha igazán kezdünk látni ezeket 

00:14:01.790 --> 00:14:07.720
 dolog, így úgy gondolom, mint a hadnagy 

00:14:03.920 --> 00:14:10.579
 az adatok magukra gondolnak 

00:14:07.720 --> 00:14:13.279
 itt van a kihívás, így mondtam 

00:14:10.579 --> 00:14:15.499
 ez a számítógép itt a kihívás 

00:14:13.279 --> 00:14:17.180
 kell, hogy a színek megfeleljenek igen 

00:14:15.499 --> 00:14:19.069
 SATA-bukás miatt, amit mondtak 

00:14:17.180 --> 00:14:21.649
 ez az, ami az 

00:14:19.069 --> 00:14:24.529
 ez a végső játék és a számítógép 

00:14:21.649 --> 00:14:27.740
 azt mondta, oké boom boo-boom boo-boom gondolta 

00:14:24.529 --> 00:14:29.779
 ki, és próba és hiba, és hmm 

00:14:27.740 --> 00:14:30.410
 talán, ha megpróbálom, és kitaláltam volna 

00:14:29.779 --> 00:14:33.079
 jobb 

00:14:30.410 --> 00:14:34.550
 nem, és mint ez csodálatos, és a 

00:14:33.079 --> 00:14:36.889
 tény, hogy csak egy másodperc alatt tettem 

00:14:34.550 --> 00:14:38.899
 mint egy másodperc van, nincs 

00:14:36.889 --> 00:14:40.399
 a történet alig több mint egy másodperc 

00:14:38.899 --> 00:14:42.470
 az oldószer csak egy másodperc alatt van 

00:14:40.399 --> 00:14:44.480
 csodálatos így megoldotta, de kitalálta 

00:14:42.470 --> 00:14:46.850
 nem csak úgy, mintha nem mondanák 

00:14:44.480 --> 00:14:48.230
 oké, programozom, hogy megfordítsam 

00:14:46.850 --> 00:14:50.360
 Ily módon fordítsuk meg azt így 

00:14:48.230 --> 00:14:53.269
 így nem mondták, hogy ez az 

00:14:50.360 --> 00:14:56.569
 mit kell tenned, hogy megoldd, és a 

00:14:53.269 --> 00:14:59.420
 a számítógép rájött, hogy csodálatos 

00:14:56.569 --> 00:15:02.929
 technológia, amely megváltoztatja a világot 

00:14:59.420 --> 00:15:04.459
 Igen biztos, hogy így van 

00:15:02.929 --> 00:15:08.740
 pozitív oldala azt mondja ehhez hasonlónak 

00:15:04.459 --> 00:15:12.410
 technológia hogyan lehet megoldani egy 

00:15:08.740 --> 00:15:15.949
 környezeti válság hogyan tudjuk elérni a 

00:15:12.410 --> 00:15:19.189
 az olajfolt az öbölből jobbra és 

00:15:15.949 --> 00:15:20.839
 és ez az, hogy ez az ötlet 

00:15:19.189 --> 00:15:22.309
 azt a pontot fogjuk elérni, ahol mi 

00:15:20.839 --> 00:15:24.559
 megkérdezheti az ilyen típusú kérdéseket 

00:15:22.309 --> 00:15:26.449
 Egy számítógép AI-je, amelyről úgy gondolja, hogy a Google gyors 

00:15:24.559 --> 00:15:27.949
 úgy gondolja, hogy a Google lenyűgöző 

00:15:26.449 --> 00:15:28.490
 az eredmények jól fogják robbantani 

00:15:27.949 --> 00:15:30.319
 elme 

00:15:28.490 --> 00:15:31.980
 biztos ez a történet ez a történet 

00:15:30.319 --> 00:15:34.410
 engem hmm-nek tesz 

00:15:31.980 --> 00:15:36.569
 egy kicsit az a tény, hogy megoldódott 

00:15:34.410 --> 00:15:38.069
 teljesen más logikával 

00:15:36.569 --> 00:15:39.600
 mint az emberek igen 

00:15:38.069 --> 00:15:41.220
 és ha másképp gondolkodik, akkor mit tesz 

00:15:39.600 --> 00:15:44.910
 csodálatos, de ha szeretnének 

00:15:41.220 --> 00:15:47.549
 az AI utánozza az embereket, hogy lehetővé tegye 

00:15:44.910 --> 00:15:49.980
 a munka, hogy ezt megtegye, és megy rendben 

00:15:47.549 --> 00:15:53.399
 Mi a helyzet ezzel az összetett dologgal, amit mi 

00:15:49.980 --> 00:15:55.350
 nem tudtam kitalálni, ami vezet 

00:15:53.399 --> 00:15:57.419
 logikus gondolat, hogy azt mondja, hogy ez lesz 

00:15:55.350 --> 00:15:58.379
 találjunk megoldást, amit nem tudunk 

00:15:57.419 --> 00:16:01.529
 tekerje a fejünket 

00:15:58.379 --> 00:16:04.589
 ez az elkerülhetetlen kérdés 

00:16:01.529 --> 00:16:06.509
 vezéreljük az AI-t, így azt mondanám a legnagyobb 

00:16:04.589 --> 00:16:07.889
 kérdésem most, és azt hiszem 

00:16:06.509 --> 00:16:09.720
 ennek a történetnek az egész része 

00:16:07.889 --> 00:16:11.819
 izgatja a legtöbbet, hogy nem 

00:16:09.720 --> 00:16:13.350
 erről szól a Rubik kocka 

00:16:11.819 --> 00:16:15.929
 hogyan gondolkodik rendben, hogyan állítunk be 

00:16:13.350 --> 00:16:18.389
 az AI programozása, hogy úgy gondoljuk, mint mi 

00:16:15.929 --> 00:16:19.799
 amikor meg tudták csinálni, ez egy egész 

00:16:18.389 --> 00:16:22.139
 Jobb játékváltó, mert akkor megy 

00:16:19.799 --> 00:16:24.449
 Hé, hogyan oldjuk meg a nagy szemetet 

00:16:22.139 --> 00:16:26.009
 A csendes-óceáni csempe kettős 

00:16:24.449 --> 00:16:28.619
 a Texas mérete jól megy 

00:16:26.009 --> 00:16:31.199
 így igen, mint a válasz 

00:16:28.619 --> 00:16:33.299
 és amikor Martin Ford jött a show-ra 

00:16:31.199 --> 00:16:36.929
 beszélj mesterséges intelligenciáról és 

00:16:33.299 --> 00:16:38.819
 és hol vannak most, mint a 

00:16:36.929 --> 00:16:41.220
 egy olyan szerzőt, mint az általa használt területen 

00:16:38.819 --> 00:16:44.850
 olyan példák, mint mi 

00:16:41.220 --> 00:16:48.569
 értsd meg a folyamatot, hogy az AI 

00:16:44.850 --> 00:16:49.860
 használja, hogy elérje a szükséges megoldást 

00:16:48.569 --> 00:16:52.529
 hogy megértsük, hogy szükségünk van rá 

00:16:49.860 --> 00:16:55.470
 ellenőrzése, mert egy egyszerű kérés 

00:16:52.529 --> 00:17:00.089
 AI azt mondja, hogy az ő példájában 

00:16:55.470 --> 00:17:02.220
 az volt, hogy a gemkapocs-vállalatainkat többet hozza 

00:17:00.089 --> 00:17:04.529
 hatékony, majd hirtelen a 

00:17:02.220 --> 00:17:07.500
 Az AI átveszi és ezzel együtt nem 

00:17:04.529 --> 00:17:10.620
 idő, amennyit az AI hasonló 

00:17:07.500 --> 00:17:13.230
 erőforrások húzása mindenhol és 

00:17:10.620 --> 00:17:15.569
 egy hatékony gemkapocs-társaság létrehozása 

00:17:13.230 --> 00:17:18.419
 az a pont, ahol most az emberi civilizáció 

00:17:15.569 --> 00:17:21.329
 elpusztult, de a gémkapcsok még mindig vannak 

00:17:18.419 --> 00:17:23.189
 nagyon hatékonyan gyártjuk 

00:17:21.329 --> 00:17:26.909
 nekünk kell irányítanunk, amit ténylegesen meg kell tennünk 

00:17:23.189 --> 00:17:31.830
 értsd meg az AI folyamatát 

00:17:26.909 --> 00:17:33.720
 a gondolkodás igaza van, és tudod 

00:17:31.830 --> 00:17:35.519
 a fejünk körül, ami most kemény 

00:17:33.720 --> 00:17:37.740
 tudod, ha nem gondolják 

00:17:35.519 --> 00:17:38.820
 mint mi, egyetértek azzal, hogy tudjuk, hogy van 

00:17:37.740 --> 00:17:39.840
 csevegőszoba pénz, ahogy beszélünk 

00:17:38.820 --> 00:17:41.549
 ez és az élelmiszer újdonságot jelent 

00:17:39.840 --> 00:17:43.720
 kérdés az, hogy hányszor volt az AI 

00:17:41.549 --> 00:17:45.760
 először megoldania kell a puzzle-t 

00:17:43.720 --> 00:17:48.549
 ez érdekes lenne 

00:17:45.760 --> 00:17:50.740
 Egy egyszerű oh ez a helyzet I 

00:17:48.549 --> 00:17:51.970
 végre kell hajtanod néhány farts rendben van, vagy megcsináltad 

00:17:50.740 --> 00:17:54.429
 tényleg próbára és hibára megy át 

00:17:51.970 --> 00:17:56.530
 Érdekes lenne tudni, hogy szeretném 

00:17:54.429 --> 00:17:57.970
 képzeljük el, és nincs 

00:17:56.530 --> 00:17:59.830
 válaszoljon erre, és ez nem az 

00:17:57.970 --> 00:18:01.870
 hír, de azt hiszem, hogy olyan 

00:17:59.830 --> 00:18:03.789
 a megtanulta, majd képes volt 

00:18:01.870 --> 00:18:06.340
 jobban megoldja, ha megtanultam 

00:18:03.789 --> 00:18:09.700
 nem hiszem, hogy az egy másodperc benne van 

00:18:06.340 --> 00:18:11.169
 a tanulás és a kitalálás, hogyan kell 

00:18:09.700 --> 00:18:13.059
 majd amikor bemutatták vele 

00:18:11.169 --> 00:18:16.750
 miután megtanulta, hogyan kell kezelni a 

00:18:13.059 --> 00:18:19.000
 Rubik kocka, mint egy emberi gyermek 

00:18:16.750 --> 00:18:22.150
 ez így mozoghat, és 

00:18:19.000 --> 00:18:24.220
 így van idő ó, igen igen igen 

00:18:22.150 --> 00:18:25.900
 azt tanítanod kell, de ez egy 

00:18:24.220 --> 00:18:31.000
 jó kérdés, hogy fogunk jelenteni 

00:18:25.900 --> 00:18:34.900
 hogy az egyikhez kérem az Intel-t 

00:18:31.000 --> 00:18:38.080
 bemutatta új AI rendszerét Pahokee strandját 

00:18:34.900 --> 00:18:40.539
 ez egy morális morphic számítógép 

00:18:38.080 --> 00:18:43.630
 képes nyolc millió szimulálására 

00:18:40.539 --> 00:18:45.750
 idegsejtek neuromorf szerkezete is 

00:18:43.630 --> 00:18:48.429
 neuromorf számítástechnikának nevezik 

00:18:45.750 --> 00:18:51.340
 leírja a rendszereket tartalmazó rendszerek használatát 

00:18:48.429 --> 00:18:53.919
 elektronikus analóg áramkörök utánozni 

00:18:51.340 --> 00:18:56.440
 neurobiológiai architektúra 

00:18:53.919 --> 00:18:58.480
 az idegrendszer jelenléte 

00:18:56.440 --> 00:19:00.400
 a neuromorf kutatás a 

00:18:58.480 --> 00:19:03.640
 szuperszámítógép több ezer alkalommal 

00:19:00.400 --> 00:19:06.190
 a DARPA-nál ma erőteljesebb 

00:19:03.640 --> 00:19:09.340
 elektronikai újjáéledési kezdeményezés csúcstalálkozó 

00:19:06.190 --> 00:19:11.020
 Detroitban hétfőn az Intel bemutatta a 64-et 

00:19:09.340 --> 00:19:14.860
 chipmodell, amely képes szimulálni 

00:19:11.020 --> 00:19:17.940
 összesen nyolc millió neuron az Intelben 

00:19:14.860 --> 00:19:20.919
 A labs ügyvezető igazgató gazdag uhlig mondta 

00:19:17.940 --> 00:19:23.710
 A Pahokee strand elérhető lesz 

00:19:20.919 --> 00:19:26.140
 hatvan kutatópartner az előrejelzéshez 

00:19:23.710 --> 00:19:29.049
 a mező végét idézzük és növeljük az AI-t 

00:19:26.140 --> 00:19:35.169
 algoritmusok, mint például tartalék kódolás és út 

00:19:29.049 --> 00:19:38.230
 tervezett pokey Beach pack 64 alacsony kulcs 128 

00:19:35.169 --> 00:19:40.600
 a 14 nanométeres mag és a neuromorf chipek 

00:19:38.230 --> 00:19:46.150
 melyeket októberben elsőként részletezték 

00:19:40.600 --> 00:19:49.659
 2017 minden egyes alacsonyabb loi-processzor 60-as 

00:19:46.150 --> 00:19:53.380
 milliméteres halálméret és több mint kettő 

00:19:49.659 --> 00:19:55.190
 milliárd mesterséges tranzisztor 

00:19:53.380 --> 00:19:57.950
 neuronok és 100 

00:19:55.190 --> 00:20:00.290
 és 30 millió szinapszis mellett 

00:19:57.950 --> 00:20:03.320
 három irányító tó a magok számára 

00:20:00.290 --> 00:20:07.130
 feladatfelvétel az Intel szerint 

00:20:03.320 --> 00:20:09.020
 A Loy akár 1000-et is feldolgoz 

00:20:07.130 --> 00:20:11.810
 gyorsabban és 10 000-szer nagyobb 

00:20:09.020 --> 00:20:13.760
 hatékonyabb, mint a hagyományos feldolgozók 

00:20:11.810 --> 00:20:15.800
 és képes megoldani bizonyos típusokat 

00:20:13.760 --> 00:20:18.770
 optimalizálási problémák több mint 

00:20:15.800 --> 00:20:21.230
 három nagyságrenddel növekszik a sebesség 

00:20:18.770 --> 00:20:24.140
 és az energiahatékonysághoz képest 

00:20:21.230 --> 00:20:26.690
 a hagyományos CPU műveletek a chipet 

00:20:24.140 --> 00:20:29.660
 körülbelül 100-szor kevesebb energiát fogyaszt 

00:20:26.690 --> 00:20:33.140
 mint a széles körben használt CPU futásszimuláció 

00:20:29.660 --> 00:20:35.240
 helymeghatározási és térképezési módszerek Az Intel azt mondja 

00:20:33.140 --> 00:20:38.810
 hogy az idén később bevezetésre kerül 

00:20:35.240 --> 00:20:42.380
 egy még nagyobb llahi rendszer Pahokee 

00:20:38.810 --> 00:20:44.750
 Rugók, amelyek nem jeleznek 

00:20:42.380 --> 00:20:47.240
 példátlan teljesítményszint és 

00:20:44.750 --> 00:20:52.910
 a neuromorf terhelések hatékonysága 

00:20:47.240 --> 00:20:54.410
 100 millió neuron felfelé, de 

00:20:52.910 --> 00:20:57.200
 nem fedték le a giggle pontszámot 

00:20:54.410 --> 00:20:59.210
 igen, három pontot emlékszel 

00:20:57.200 --> 00:21:04.850
 amikor a feldolgozók nagyon barátságosak voltak 

00:20:59.210 --> 00:21:08.680
 olyan nevek, mint Pentium Celeron 

00:21:04.850 --> 00:21:12.590
 minden olyan, mint egy idegen szó 

00:21:08.680 --> 00:21:15.500
 ez tényleg kemény, de megkapja a lényeget 

00:21:12.590 --> 00:21:19.580
 belőle - mikor lehet hozzáadni a titkosítást 

00:21:15.500 --> 00:21:23.780
 bányászok erre és igen 

00:21:19.580 --> 00:21:24.980
 a harmadik kérdés olyan, mintha, és nem 

00:21:23.780 --> 00:21:27.290
 tényleg egy kérdés, de inkább a 

00:21:24.980 --> 00:21:30.280
 nyilatkozat, hogyan látja a technológiát 

00:21:27.290 --> 00:21:33.860
 haladt, és most hallotta 

00:21:30.280 --> 00:21:39.470
 a processzorokat kifejezetten leírják 

00:21:33.860 --> 00:21:42.890
 az ilyen neuronok és poszteronok 

00:21:39.470 --> 00:21:47.330
 a Star Trek dolgai olyanok, mint mi vagyunk 

00:21:42.890 --> 00:21:54.610
 az agyról beszél, ez az agy 8-as 

00:21:47.330 --> 00:22:00.650
 millió ezer neuron 

00:21:54.610 --> 00:22:03.230
 így azt hiszem, hogy egy milliárd vagyok 

00:22:00.650 --> 00:22:06.800
 jobb agy, mint nincs semmi gosh 

00:22:03.230 --> 00:22:08.900
 nem nem gyorsabb nem ismerem őket 

00:22:06.800 --> 00:22:11.510
 igen, ez nem hasonlítható össze 

00:22:08.900 --> 00:22:15.230
 egy emberi agy, de ismét visszatér 

00:22:11.510 --> 00:22:17.780
 tudva, hogy a számítógépek elindulnak 

00:22:15.230 --> 00:22:20.570
 azt hiszem, és most 

00:22:17.780 --> 00:22:22.520
 kiépítik az agyat a számítógépből 

00:22:20.570 --> 00:22:25.300
 zsetonok most már az, amit tudni akarok 

00:22:22.520 --> 00:22:27.440
 hogyan hasonlítható össze Watson Oh-val 

00:22:25.300 --> 00:22:31.250
 Watson semmi ehhez képest 

00:22:27.440 --> 00:22:34.460
 igaza van, mint a történetben 

00:22:31.250 --> 00:22:38.540
 beszélünk arról, hogy ez hogyan lehet ezer 

00:22:34.460 --> 00:22:41.840
 gyorsabb, mint bármely szuperszámítógép 

00:22:38.540 --> 00:22:42.980
 létezik ma az én számomban, hogyan 

00:22:41.840 --> 00:22:45.080
 sok a közeljövőben 

00:22:42.980 --> 00:22:46.370
 Watson igen, ez minden, amit meg fogunk csinálni 

00:22:45.080 --> 00:22:50.960
 csináld ezt, és ahogyan azt tényleg meg fogod csinálni 

00:22:46.370 --> 00:22:53.150
 jobb legyen a hiba miatt, igen, ismét kérje 

00:22:50.960 --> 00:22:55.700
 ez a kérdés hogyan lehet megoldani a világot 

00:22:53.150 --> 00:23:00.020
 éhség, amit tudsz, csak válaszoljon nekem 

00:22:55.700 --> 00:23:02.990
 jó először is van, amit kaptam 

00:23:00.020 --> 00:23:04.130
 néhány javaslat, így ez lesz 

00:23:02.990 --> 00:23:07.220
 segíteni fog az ilyen dolgoknál 

00:23:04.130 --> 00:23:09.740
 ha a jobb kezek között van mm-hmm és 

00:23:07.220 --> 00:23:11.900
 ez az, hogy csak dió, mint én vagyok 

00:23:09.740 --> 00:23:14.600
 Teljesen elgondolkodtam a lényegre 

00:23:11.900 --> 00:23:17.060
 a nyelv megkötött, mert mindent elhelyeztem 

00:23:14.600 --> 00:23:19.250
 így tetszik az adatok összefüggésében, mert 

00:23:17.060 --> 00:23:22.450
 és a Star Trek karaktert 

00:23:19.250 --> 00:23:25.730
 mert ez egy pozitronikus háló, ami a 

00:23:22.450 --> 00:23:28.870
 Neuromorf számítógép jobb és most 

00:23:25.730 --> 00:23:31.840
 tényleg rendben van, mint a pont 

00:23:28.870 --> 00:23:34.580
 mint ez a kezdetleges 

00:23:31.840 --> 00:23:37.220
 a gyűlölet bevezető változata 

00:23:34.580 --> 00:23:38.870
 az AI technológia most úgy gondolja 

00:23:37.220 --> 00:23:40.970
 önmagában megtanulhatja, hogyan oldja meg a 

00:23:38.870 --> 00:23:42.860
 Rubik kocka egy másodperc alatt, és van 

00:23:40.970 --> 00:23:45.950
 a technológia gyorsabbá tétele és készítése 

00:23:42.860 --> 00:23:51.020
 hogy egy nagyon nagyon gondolkodni tudjon 

00:23:45.950 --> 00:23:53.390
 gyorsan, úgy, mintha technikában dolgozol 

00:23:51.020 --> 00:23:55.790
 igen, és sokan nem dolgoznak a 

00:23:53.390 --> 00:23:57.560
 Szeretem ezt a cuccot, mint az enyém 

00:23:55.790 --> 00:23:59.810
 sok szolgáltatást hív, és tetszik 

00:23:57.560 --> 00:24:03.110
 a színezett emberek el tudják képzelni, ha 

00:23:59.810 --> 00:24:05.480
 volt egy AI, mint egy mikro 

00:24:03.110 --> 00:24:08.900
 ennek a cégnek a megvásárolt változata 

00:24:05.480 --> 00:24:11.800
 mmm, amely lehetővé tette, hogy a VPN az emberekbe 

00:24:08.900 --> 00:24:13.700
 otthoni számítógépek a probléma megoldásához 

00:24:11.800 --> 00:24:15.980
 automatikusan meg tudná képzelni őket 

00:24:13.700 --> 00:24:18.290
 hogyan változtatná meg az iparodat mmm 

00:24:15.980 --> 00:24:20.810
 sok az én iparomban 

00:24:18.290 --> 00:24:21.990
 felesleges, és ez azt jelenti, mintha 

00:24:20.810 --> 00:24:24.990
 ismétlődő igen 

00:24:21.990 --> 00:24:26.190
 mindig ugyanaz a dolog, de azt hiszem 

00:24:24.990 --> 00:24:29.100
 ilyesmit veszel, hogy menjenek 

00:24:26.190 --> 00:24:31.620
 mintha igen, hogyan és hogyan beszélhetnék én 

00:24:29.100 --> 00:24:34.340
 azt jelenti, hogy beszéljen az Amazon visszhangjával és legyen 

00:24:31.620 --> 00:24:37.410
 úgy hangzik, mintha egy személy lenne 

00:24:34.340 --> 00:24:39.750
 tudnak beszélni, hogy tudják 

00:24:37.410 --> 00:24:42.480
 itt mindenféle baljós dolog van 

00:24:39.750 --> 00:24:44.520
 de ha a jobb kezekben ez lehet 

00:24:42.480 --> 00:24:47.070
 nagyon jó eszköz a jó jobbra 

00:24:44.520 --> 00:24:49.410
 ezt most már bemutatták és 

00:24:47.070 --> 00:24:54.030
 fejlett, de autonóm járművek 

00:24:49.410 --> 00:24:56.700
 már ott van, igen, nem nem, de 

00:24:54.030 --> 00:25:00.720
 az interneten keresztül nagyon Wi-Fi-n keresztül 

00:24:56.700 --> 00:25:04.800
 LTE vagy 5g vagy bármi, amit akarsz 

00:25:00.720 --> 00:25:06.660
 olyan, mintha mindig összekapcsolt volna 

00:25:04.800 --> 00:25:08.520
 most hirtelen van ilyen 

00:25:06.660 --> 00:25:11.700
 a neurális hálózatot tápláló agy 

00:25:08.520 --> 00:25:13.740
 önálló járművek rendben van 

00:25:11.700 --> 00:25:15.210
 emlékezz arra, hogy évet fogok mondani, és a 

00:25:13.740 --> 00:25:16.500
 félévente fél évvel ezelőtt 

00:25:15.210 --> 00:25:18.300
 ha van egy hír, de mi van 

00:25:16.500 --> 00:25:19.530
 beszéltem egy tonna járműről és én 

00:25:18.300 --> 00:25:21.570
 azt mondta, nem lenne csodálatos, ha tudjuk 

00:25:19.530 --> 00:25:25.020
 elérje azt a pontot, ahol a forgalom 

00:25:21.570 --> 00:25:27.270
 az összekapcsolt autókon keresztül történő vezetés 

00:25:25.020 --> 00:25:29.429
 a pillanatnyi hely, ahol alapul 

00:25:27.270 --> 00:25:30.480
 az emberek vezetési szokásai munkájukat 

00:25:29.429 --> 00:25:32.010
 óra igen 

00:25:30.480 --> 00:25:33.270
 olvassák le a menetrendjüket, és most mi vagyunk 

00:25:32.010 --> 00:25:34.860
 a magánélethez és mindenféle dolghoz 

00:25:33.270 --> 00:25:36.120
 de biztos tudod, hogy tudod, hogy elolvastál 

00:25:34.860 --> 00:25:38.040
 az Ön Google Conner-jét, ahová kellene 

00:25:36.120 --> 00:25:40.140
 A meghajtó ideje, hogy menjen, el kell hagynia 

00:25:38.040 --> 00:25:41.610
 ezúttal úgy, hogy megteszi ezt a kijáratot 

00:25:40.140 --> 00:25:44.460
 Kilépés és van egy számítógép valahol 

00:25:41.610 --> 00:25:46.620
 ez az összes autonóm autót irányítja 

00:25:44.460 --> 00:25:48.570
 ez olyan, mint te csak menj, jó vagyok 

00:25:46.620 --> 00:25:51.179
 pillanatban repülnek taxik 

00:25:48.570 --> 00:25:55.320
 igen, és add hozzá a mixhez 

00:25:51.179 --> 00:25:58.770
 nincs okod, hogy későn legyél 

00:25:55.320 --> 00:26:01.800
 a számítógép időben készült, ez egy csodálatos 

00:25:58.770 --> 00:26:03.929
 hadd vessen egy pillantást a 

00:26:01.800 --> 00:26:06.630
 cryptocurrency piacon ez így van 

00:26:03.929 --> 00:26:09.540
 2019-ben a neurális előtt néz ki 

00:26:06.630 --> 00:26:12.030
 hálózata lehetővé teszi számunkra, hogy hatalmas 

00:26:09.540 --> 00:26:15.179
 Bitcoin mennyisége így van 

00:26:12.030 --> 00:26:17.220
 A Bitcoin 9700-nál ül 

00:26:15.179 --> 00:26:20.220
 dollárt és 67 centet mondok 

00:26:17.220 --> 00:26:24.120
 minden Bitcoin Bitcoin vesztes 

00:26:20.220 --> 00:26:27.420
 bár ez a legnagyobb vesztes 2137 

00:26:24.120 --> 00:26:30.540
 dollárt és 35 centet az utoljára 

00:26:27.420 --> 00:26:31.980
 héten a Facebook Libre még mindig ül 

00:26:30.540 --> 00:26:33.570
 nulla dollár, és megtartom 

00:26:31.980 --> 00:26:35.200
 ezt mondja, mert egy nap ez 

00:26:33.570 --> 00:26:36.789
 megéri egy fillért 

00:26:35.200 --> 00:26:38.919
 és akkor ez az, amikor tudjuk 

00:26:36.789 --> 00:26:41.019
 A Facebook valójában mit csinál 

00:26:38.919 --> 00:26:42.549
 azt mondta, hogy megcsinálják 

00:26:41.019 --> 00:26:46.510
 kilencven dollárt és három centt 

00:26:42.549 --> 00:26:47.980
 tizenhat és 72 centi éteriumot két 

00:26:46.510 --> 00:26:50.919
 száz és tizenhárom dollár és 72 

00:26:47.980 --> 00:26:53.769
 centre monaro hetvenhét ötven kilenc 

00:26:50.919 --> 00:26:56.440
 most a nyomaték nulla pont kilenc hat tíz 

00:26:53.769 --> 00:26:59.169
 század ezer és teknős érme 

00:26:56.440 --> 00:27:00.669
 nulla pontban is kilenc nyolc tíz 

00:26:59.169 --> 00:27:01.809
 század ezer része emlékszik, ha 

00:27:00.669 --> 00:27:04.600
 az enyém lesz, ha meg akarod csinálni 

00:27:01.809 --> 00:27:06.909
 befektetni vagy más módon dolgozni 

00:27:04.600 --> 00:27:09.250
 cryptocurrency ez egy olyan piac, amely soha nem 

00:27:06.909 --> 00:27:11.919
 bezár, és ez egy olyan piac, amely mindig 

00:27:09.250 --> 00:27:15.510
 az illékony, így legyen óvatos és csak költeni 

00:27:11.919 --> 00:27:18.460
 csak befektetni, ahol megengedheti magának, hogy elveszítheti 

00:27:15.510 --> 00:27:19.990
 nagy köszönet Roy W Nashnek és a miénknek 

00:27:18.460 --> 00:27:21.880
 a nézők közössége 

00:27:19.990 --> 00:27:23.950
 mesélnek nekünk ezen a héten 

00:27:21.880 --> 00:27:25.960
 az ötödik kategóriás tv-hírcsatornát nézi 

00:27:23.950 --> 00:27:27.909
 ne felejtsd el, hogy tetszik és feliratkozik 

00:27:25.960 --> 00:27:29.769
 az összes technikai híred enyhe Linux-tal 

00:27:27.909 --> 00:27:31.510
 az elfogultság és a több szabad tartalom biztosítása 

00:27:29.769 --> 00:27:33.730
 hogy megnézze honlapunkat a 

00:27:31.510 --> 00:27:35.860
 öt kategóriás TV hírcsarnok vagyok Sasha 

00:27:33.730 --> 00:27:38.309
 Rickman és én vagyok Robbie Ferguson és én vagyok 

00:27:35.860 --> 00:27:38.309
 Jeff Lester 

00:27:42.860 --> 00:27:48.640
 [Zene] 

00:27:46.560 --> 00:27:58.640
 [Taps] 

00:27:48.640 --> 00:27:58.640
 [Zene] 

