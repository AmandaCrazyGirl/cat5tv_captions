WEBVTT
Kind: captions
Language: nl

00:00:00.030 --> 00:00:05.009
 hier zijn de verhalen die dit bedekken 

00:00:01.949 --> 00:00:06.960
 week in de newsroom van de categorie 5 TV 

00:00:05.009 --> 00:00:08.880
 besloten Facebook krijgt een boete a 

00:00:06.960 --> 00:00:11.460
 maar liefst vijf miljard dollar over de 

00:00:08.880 --> 00:00:14.040
 Cambridge analytisch schandaal de volledig 

00:00:11.460 --> 00:00:17.060
 interactief een Doctor Who VR game de 

00:00:14.040 --> 00:00:19.439
 tijdsbestek arriveert in september een 

00:00:17.060 --> 00:00:21.420
 kunstmatige intelligentiesysteem gemaakt 

00:00:19.439 --> 00:00:23.670
 door onderzoekers van de universiteit van 

00:00:21.420 --> 00:00:27.300
 Californië heeft de Rubik's Cube opgelost 

00:00:23.670 --> 00:00:30.779
 in iets meer dan een seconde en Intel heeft 

00:00:27.300 --> 00:00:33.960
 onthulde zijn nieuwe AI-systeem Hawaii Beach 

00:00:30.779 --> 00:00:36.809
 het is een neuromorfische computer die in staat is 

00:00:33.960 --> 00:00:38.280
 acht miljoen neuronen simuleren deze 

00:00:36.809 --> 00:00:41.280
 verhalen komen eraan 

00:00:38.280 --> 00:00:44.340
 ga nergens heen dit is de categorie 5 

00:00:41.280 --> 00:00:50.640
 TV-redactie over de toptechnologie van de week 

00:00:44.340 --> 00:00:52.680
 verhalen zijn een Linux door ons ik ben sasha 

00:00:50.640 --> 00:00:54.809
 Rickman en hij lazen de topverhalen waren 

00:00:52.680 --> 00:00:56.489
 na deze week is besloten 

00:00:54.809 --> 00:00:57.870
 Facebook krijgt maar liefst 5 beboet 

00:00:56.489 --> 00:01:00.059
 miljard dollar over de Cambridge 

00:00:57.870 --> 00:01:02.370
 analytisch een schandaal voor de consument 

00:01:00.059 --> 00:01:05.010
 Protection Agency in de VS de federale 

00:01:02.370 --> 00:01:07.320
 Trade Commission FTC begon onderzoek te doen 

00:01:05.010 --> 00:01:09.479
 Facebook in maart 2018 volgt 

00:01:07.320 --> 00:01:11.970
 meldt dat Cambridge analytische ah had 

00:01:09.479 --> 00:01:14.549
 toegang tot de gegevens van tientallen miljoenen 

00:01:11.970 --> 00:01:16.759
 zijn gebruikers als het blijkt dat het als het 

00:01:14.549 --> 00:01:20.100
 politiek adviesbureau was in staat om 

00:01:16.759 --> 00:01:23.580
 onjuiste gegevens van maximaal 87 

00:01:20.100 --> 00:01:26.070
 miljoen Facebook-gebruikers het onderzoek 

00:01:23.580 --> 00:01:28.619
 gericht op het feit of Facebook had geschonden 

00:01:26.070 --> 00:01:30.990
 een overeenkomst van 2011 waarin het was 

00:01:28.619 --> 00:01:34.170
 vereist om gebruikers duidelijk te informeren en 

00:01:30.990 --> 00:01:37.170
 verkrijgen uitdrukkelijke toestemming om hun gegevens te delen 

00:01:34.170 --> 00:01:39.030
 bij een drie-tegen-twee stem het record 5 

00:01:37.170 --> 00:01:41.939
 een miljardenafrekening werd goedgekeurd 

00:01:39.030 --> 00:01:43.680
 door de FTC moet de boete nog steeds zijn 

00:01:41.939 --> 00:01:45.930
 gefinaliseerd door het ministerie van Justitie 

00:01:43.680 --> 00:01:49.290
 Civil Division en het is onduidelijk hoe 

00:01:45.930 --> 00:01:51.420
 Dit kan lang duren als dit wordt bevestigd 

00:01:49.290 --> 00:01:54.540
 de grootste boete zijn die ooit door de 

00:01:51.420 --> 00:01:56.969
 FTC op een techbedrijf dat Facebook was geweest 

00:01:54.540 --> 00:01:59.280
 verwachtend dit vertelde het investeerders binnen 

00:01:56.969 --> 00:02:01.469
 April dat het het grootste deel van het 

00:01:59.280 --> 00:02:04.170
 geld wat betekent dat het de firma niet wil 

00:02:01.469 --> 00:02:07.259
 voel veel extra financiële spanning van 

00:02:04.170 --> 00:02:09.629
 deze boete wat we nog niet weten is 

00:02:07.259 --> 00:02:12.180
 welke aanvullende maatregelen kunnen worden getroffen 

00:02:09.629 --> 00:02:13.410
 op het bedrijf zoals verhoogde privacy 

00:02:12.180 --> 00:02:14.640
 overzicht of 

00:02:13.410 --> 00:02:16.500
 als er enig persoonlijk is 

00:02:14.640 --> 00:02:19.260
 repercussies voor het hoofd van het bedrijf 

00:02:16.500 --> 00:02:21.630
 uitvoerende Mark Zuckerberg de nederzetting 

00:02:19.260 --> 00:02:23.730
 wat neerkomt op ongeveer een kwart van 

00:02:21.630 --> 00:02:25.710
 de jaarlijkse winst van het bedrijf zal 

00:02:23.730 --> 00:02:27.450
 reignite kritiek van degenen die zeggen 

00:02:25.710 --> 00:02:29.270
 dat de boete niet veel meer is dan a 

00:02:27.450 --> 00:02:33.180
 tik op de vingers 

00:02:29.270 --> 00:02:37.550
 hmm vijf miljard dollar is geen klap 

00:02:33.180 --> 00:02:40.110
 aan de pols voelt een beetje een beetje groter 

00:02:37.550 --> 00:02:44.250
 $ 2,00 is een grote boete 

00:02:40.110 --> 00:02:46.410
 het is ja ik denk niet dat ik niet denk 

00:02:44.250 --> 00:02:49.740
 dat ze de boete zullen negeren 

00:02:46.410 --> 00:02:51.570
 gelijk maar ga door, ze hebben het al gedaan 

00:02:49.740 --> 00:02:54.990
 het grootste deel van dat geld weg kunnen we dat is 

00:02:51.570 --> 00:02:58.380
 niet zeggen had toegang tot de meeste Oh geld te nemen 

00:02:54.990 --> 00:03:02.160
 dat wilt u van ons overschot 

00:02:58.380 --> 00:03:03.900
 om het pijn te doen ga je verder dan dat 

00:03:02.160 --> 00:03:06.650
 eerlijk gezegd denk ik wel dat het een klap was op de 

00:03:03.900 --> 00:03:09.300
 pols en ik las een artikel dat 

00:03:06.650 --> 00:03:11.190
 er was een sprong in aandelen na de 

00:03:09.300 --> 00:03:14.310
 boete werd aangekondigd mm-hmm waarom ik nee heb 

00:03:11.190 --> 00:03:15.540
 Aanwijzing maar de sprong in aandelen bijna 

00:03:14.310 --> 00:03:20.550
 produceert dezelfde hoeveelheid geld die zij 

00:03:15.540 --> 00:03:22.500
 werden beboet Wow mensen zijn verliefd dus 

00:03:20.550 --> 00:03:24.060
 het is net Oh Papa, verdomd goed 

00:03:22.500 --> 00:03:25.970
 Facebook oh we hebben net het geld terugverdiend 

00:03:24.060 --> 00:03:28.380
 zoals Timmy, dat is stom 

00:03:25.970 --> 00:03:30.420
 vanuit juridisch oogpunt zoals wat als 

00:03:28.380 --> 00:03:32.280
 ze hebben bereikt dat dat is wat je bent 

00:03:30.420 --> 00:03:34.050
 ja zeggen dat ze niets hebben bereikt 

00:03:32.280 --> 00:03:36.060
 vrijwel goed wat gaan ze doen 

00:03:34.050 --> 00:03:39.959
 die vijf miljard dollar gaat het 

00:03:36.060 --> 00:03:42.709
 in de federale schatkist hmm wat ik wil 

00:03:39.959 --> 00:03:46.680
 weten dat dit gaat produceren 

00:03:42.709 --> 00:03:48.810
 rechtszaken zoals is, zal iemand zeggen dat ik ben 

00:03:46.680 --> 00:03:50.880
 je nu aanklagen Facebook je bent gevonden 

00:03:48.810 --> 00:03:52.680
 om een ​​illusie te zijn die slachtoffers ja ik 

00:03:50.880 --> 00:03:54.810
 was slachtoffer en mijn leven werd beïnvloed 

00:03:52.680 --> 00:03:57.530
 want nu zie ik deze advertenties 

00:03:54.810 --> 00:04:01.080
 dat ik nooit wilde zien voordat ik wil 

00:03:57.530 --> 00:04:02.550
 tien miljoen dollar, maar ik bedoel dat ik het kon 

00:04:01.080 --> 00:04:05.610
 zie een class-action suit uitkomen 

00:04:02.550 --> 00:04:09.660
 dit bedoel ik bedoel dat het ook gaat stijgen 

00:04:05.610 --> 00:04:11.790
 waarschijnlijk niet maar juist II gewoon 

00:04:09.660 --> 00:04:14.400
 eerlijk gezegd met al het geld dat 

00:04:11.790 --> 00:04:16.470
 Facebook maakt en al het opdringerige 

00:04:14.400 --> 00:04:17.940
 natuur dat zij hun hebben gebouwd 

00:04:16.470 --> 00:04:20.250
 bedrijf rond denk ik vijf miljoen of 

00:04:17.940 --> 00:04:22.289
 vijf miljoen is een grapje, wat zou jij doen 

00:04:20.250 --> 00:04:24.860
 stel het in op ik zou het rond hebben uitgezet 

00:04:22.289 --> 00:04:24.860
 vijftien 

00:04:24.900 --> 00:04:31.870
 Ik zou niet $ 15.000.000.000 vechten 

00:04:28.599 --> 00:04:34.870
 ja te veel, maar het andere is ik 

00:04:31.870 --> 00:04:36.039
 denk dat dit een regeling is die ik niet denk 

00:04:34.870 --> 00:04:37.539
 het was een normale zaak, denk ik 

00:04:36.039 --> 00:04:42.490
 snijd een achterkamerdeal zodat ze wisten wat 

00:04:37.539 --> 00:04:44.319
 kwam er is een positief 1/4 gedeeld 

00:04:42.490 --> 00:04:47.050
 van de jaarlijkse inkomsten als ik moest uitgeven 

00:04:44.319 --> 00:04:50.680
 een kwart van mijn inkomsten met een boete 

00:04:47.050 --> 00:04:57.400
 Ik zou de heer eten. noedels denk ik 

00:04:50.680 --> 00:05:00.550
 we zitten in een ander belastingschema zoals 

00:04:57.400 --> 00:05:03.219
 denk erover na dat fine 1/4 van hun is 

00:05:00.550 --> 00:05:06.030
 jaarlijkse inkomsten puur door het verkopen van uw 

00:05:03.219 --> 00:05:09.940
 persoonlijke gegevens dat is wat ze doen 

00:05:06.030 --> 00:05:12.340
 ja, ik verdedig Facebook onthoud ik 

00:05:09.940 --> 00:05:15.280
 ben dat zelfs NIET meer op Facebook 

00:05:12.340 --> 00:05:17.110
 hoe bedroefd ik was door dit alles 

00:05:15.280 --> 00:05:19.389
 privacy-inbreuk ja en ik denk niet 

00:05:17.110 --> 00:05:21.909
 Zuckerberg is uit het raam, dat zijn ze niet 

00:05:19.389 --> 00:05:25.000
 ga hem aanraken nee, ik zal je wat zeggen 

00:05:21.909 --> 00:05:26.500
 zoals als een gebruiker als een programmeur het geheel 

00:05:25.000 --> 00:05:29.770
 Cambridge analytisch wat doet het 

00:05:26.500 --> 00:05:31.060
 voor mij bedoeld is strikt frustrerend 

00:05:29.770 --> 00:05:33.159
 het punt waar ik alles heb geannuleerd 

00:05:31.060 --> 00:05:37.779
 Facebook-services binnen mijn bedrijf 

00:05:33.159 --> 00:05:39.580
 precies zoals ik Facebook niet meer geef 

00:05:37.779 --> 00:05:41.409
 diensten aan onze klanten Ik had iemand 

00:05:39.580 --> 00:05:42.789
 heeft me zelfs een bericht gestuurd waarin ik werd gevraagd om een 

00:05:41.409 --> 00:05:44.949
 Instagram profiel en ik zei ga 

00:05:42.789 --> 00:05:46.479
 elders ga ik het niet doen. Ik ben het niet 

00:05:44.949 --> 00:05:48.909
 Ik heb het niet over dat bedrijf 

00:05:46.479 --> 00:05:50.289
 meer zie hier is het ding dat 

00:05:48.909 --> 00:05:51.460
 stoort me een beetje over het verhaal 

00:05:50.289 --> 00:05:54.580
 en ik weet dat we door moeten gaan om te nummeren 

00:05:51.460 --> 00:05:57.099
 een waar je naar kijkt als Elon Musk de zijne maakte 

00:05:54.580 --> 00:05:59.440
 Tweet over het verwijderen van een deal in het buitenland 

00:05:57.099 --> 00:06:01.180
 of iets dat nooit is uitgekomen en 

00:05:59.440 --> 00:06:03.819
 plotseling had hij van de handel 

00:06:01.180 --> 00:06:05.349
 Commissie had een jaar van sancties voor 

00:06:03.819 --> 00:06:07.449
 Twitter en hij had iemand als een 

00:06:05.349 --> 00:06:09.370
 een ethisch persoon volgt hem en houdt van ja 

00:06:07.449 --> 00:06:11.319
 alsof er een advocaat aan verbonden was 

00:06:09.370 --> 00:06:13.599
 dus er was zo'n grote deal, mm-hmm 

00:06:11.319 --> 00:06:14.979
 terwijl Facebook miljoenen releases vrijgeeft 

00:06:13.599 --> 00:06:16.210
 persoonlijke informatie van mensen en zij 

00:06:14.979 --> 00:06:19.960
 ga ons wat geld betalen 

00:06:16.210 --> 00:06:21.729
 mm-hmm zoals waar is de impact op de 

00:06:19.960 --> 00:06:22.990
 bedrijf ja ik denk dat er een moet zijn 

00:06:21.729 --> 00:06:25.020
 heel veel meer dat erbij hoort ik 

00:06:22.990 --> 00:06:27.610
 denk dat de impact op het bedrijf is 

00:06:25.020 --> 00:06:29.830
 bedrijven zeggen dat ik het niet heb 

00:06:27.610 --> 00:06:32.560
 Facebook meer, maar kijk ik koop niet 

00:06:29.830 --> 00:06:35.289
 adverteer ruimte op Facebook nu ben ik wij 

00:06:32.560 --> 00:06:36.969
 heb een Facebook-profiel een Facebook-pagina 

00:06:35.289 --> 00:06:37.650
 voor categorie 5 TV omdat er een 

00:06:36.969 --> 00:06:39.690
 veel van 

00:06:37.650 --> 00:06:42.630
 en dus willen we dat het toegankelijk is voor 

00:06:39.690 --> 00:06:44.910
 jij maar persoonlijk gebruik ik het niet en ik 

00:06:42.630 --> 00:06:46.680
 steun het niet zoals dat is wat het is 

00:06:44.910 --> 00:06:48.900
 lijkt deze week weer opgeblazen 

00:06:46.680 --> 00:06:50.310
 mm-hmm en alle persoonlijke gegevens die dat zijn 

00:06:48.900 --> 00:06:52.860
 van die mensen worden weggenomen, gewoon niet 

00:06:50.310 --> 00:06:55.229
 zorg zoals het publiek het niet uitmaakt, maar ik 

00:06:52.860 --> 00:06:57.300
 beseffen dat het een brede strook is, ja dat doe ik niet 

00:06:55.229 --> 00:07:00.479
 graag generaliseren en mijn excuses hiervoor 

00:06:57.300 --> 00:07:02.820
 de generalisatie omdat je misschien bent 

00:07:00.479 --> 00:07:04.229
 nee zeggen kan me niet schelen het maakt me absoluut uit 

00:07:02.820 --> 00:07:05.699
 Ik heb mijn account geannuleerd of misschien ik 

00:07:04.229 --> 00:07:07.620
 heeft zich zelfs niet aangemeld voor één omdat ik dat niet heb gedaan 

00:07:05.699 --> 00:07:10.740
 akkoord gaan met hun Servicevoorwaarden maar 

00:07:07.620 --> 00:07:13.169
 het feit blijft zoals waar we ons in bevinden 

00:07:10.740 --> 00:07:16.350
 een ander tijdperk dan toen we tien jaar waren 

00:07:13.169 --> 00:07:18.870
 geleden nu de soorten diefstal van gegevensgegevens 

00:07:16.350 --> 00:07:21.510
 dat gebeurt in zaken als sociaal 

00:07:18.870 --> 00:07:24.150
 media bestonden tien jaar geleden nog niet en dus 

00:07:21.510 --> 00:07:27.210
 de wet moet inhalen we weten dat 

00:07:24.150 --> 00:07:29.130
 alsof er zoveel verschillende we kunnen 

00:07:27.210 --> 00:07:32.070
 praat over MP double-a we konden praten 

00:07:29.130 --> 00:07:36.210
 ongeveer oh ja zoals al deze dingen en 

00:07:32.070 --> 00:07:39.300
 en ze hebben nog niet ingehaald en misschien 

00:07:36.210 --> 00:07:40.650
 het is maar één stap, misschien is het dat tenminste 

00:07:39.300 --> 00:07:42.510
 niet over Facebook, misschien gaat het niet 

00:07:40.650 --> 00:07:45.210
 om deuken, maar misschien gaat het wel 

00:07:42.510 --> 00:07:47.310
 gebruikers beschermen tegen de volgende grote overtreding 

00:07:45.210 --> 00:07:50.099
 omdat de volgende grote H nog steeds op de 

00:07:47.310 --> 00:07:51.710
 up-and-up hopelijk weten we het niet echt 

00:07:50.099 --> 00:07:55.260
 grote foto's 

00:07:51.710 --> 00:07:57.210
 de volledig interactieve arts die VR-game speelt 

00:07:55.260 --> 00:07:59.820
 de rand van de tijd komt binnen 

00:07:57.210 --> 00:08:01.560
 September is de dokter gesmeten 

00:07:59.820 --> 00:08:03.780
 door de tijd tot het einde van het universum 

00:08:01.560 --> 00:08:05.930
 een virus dat uit elkaar dreigt te gaan 

00:08:03.780 --> 00:08:08.669
 de realiteit zelf is ontketend 

00:08:05.930 --> 00:08:10.440
 spelers kunnen de TARDIS besturen op een 

00:08:08.669 --> 00:08:12.630
 reis over de werelden, beide vertrouwd 

00:08:10.440 --> 00:08:15.030
 en raar om een ​​reeks te herstellen 

00:08:12.630 --> 00:08:17.130
 krachtige tijdkristallen die kunnen herstellen 

00:08:15.030 --> 00:08:19.979
 ruimte-tijd en uiteindelijk de 

00:08:17.130 --> 00:08:23.190
 universum zelf na de recente 

00:08:19.979 --> 00:08:25.680
 onthullen van de geanimeerde VR-ervaring 

00:08:23.190 --> 00:08:28.260
 Doctor Who the runaway is een nieuwe film 

00:08:25.680 --> 00:08:29.729
 feature-length Doctor Who VR-videogame 

00:08:28.260 --> 00:08:32.250
 komt in september 

00:08:29.729 --> 00:08:34.589
 gepubliceerd door play stack en ontwikkeld door 

00:08:32.250 --> 00:08:37.320
 doolhof theorie Degene aan de rand van 

00:08:34.589 --> 00:08:39.900
 de tijd zal fans wereldwijd naar de wereld brengen 

00:08:37.320 --> 00:08:41.969
 geliefde wereld van vreemdelingenmysterie en 

00:08:39.900 --> 00:08:44.010
 Ik vraag me af of ze beginnen aan een 

00:08:41.969 --> 00:08:46.470
 gloednieuw en volledig interactief 

00:08:44.010 --> 00:08:49.589
 avontuur geïnspireerd door 55 jaar van de show 

00:08:46.470 --> 00:08:51.490
 geschiedenis en met in de hoofdrol de huidige artsen 

00:08:49.589 --> 00:08:55.210
 incarnatie gespeeld door Jody 

00:08:51.490 --> 00:08:57.630
 Whitaker gewapend met de iconische sonic 

00:08:55.210 --> 00:08:59.920
 schroevendraaierplan spelers zullen oplossen 

00:08:57.630 --> 00:09:01.990
 hersenkrakende puzzels worstelen met 

00:08:59.920 --> 00:09:04.570
 klassieke monsters en nieuwe tegenkomen 

00:09:01.990 --> 00:09:06.670
 horizonten in een zoektocht om de dokter te vinden 

00:09:04.570 --> 00:09:08.680
 en versla een krachtige kracht die 

00:09:06.670 --> 00:09:11.640
 dreigt het weefsel te vernietigen 

00:09:08.680 --> 00:09:15.640
 realiteit zullen ze geconfronteerd worden met de beruchte dat 

00:09:11.640 --> 00:09:19.180
 Daleks felix Daleks ja Dalek hebben we 

00:09:15.640 --> 00:09:21.850
 een hier op de set een bekende 

00:09:19.180 --> 00:09:24.610
 gezichten van het universum van artsen plus 

00:09:21.850 --> 00:09:26.620
 een aantal gloednieuw nog nooit eerder gezien 

00:09:24.610 --> 00:09:29.080
 monsters als ze reizen door verbluffend 

00:09:26.620 --> 00:09:33.240
 filmische omgevingen die echt brengen 

00:09:29.080 --> 00:09:39.150
 de show tot leven oké dus eerst 

00:09:33.240 --> 00:09:39.150
 dat is een dollar, zoals ik ben aan het wachten 

00:09:39.330 --> 00:09:43.900
 uitroeien acteur oke dus mijn kinderen zijn 

00:09:42.640 --> 00:09:45.970
 daar zal ik blij om zijn 

00:09:43.900 --> 00:09:48.640
 enthousiast over dit eerst en vooral het 

00:09:45.970 --> 00:09:52.270
 de verhaallijn klinkt als mijn dagelijks leven 

00:09:48.640 --> 00:09:53.980
 het klinkt tegenwoordig behoorlijk cool 

00:09:52.270 --> 00:09:55.840
 ze kunnen zoveel doen en de Jodie 

00:09:53.980 --> 00:09:57.550
 Whittaker is namelijk betrokken bij de 

00:09:55.840 --> 00:10:00.070
 echt spel het gaat heel leuk worden 

00:09:57.550 --> 00:10:03.250
 voor Jodie Whittaker fans en ga naar de 

00:10:00.070 --> 00:10:06.060
 elfde Doctor fans ook, dus dit is het 

00:10:03.250 --> 00:10:08.230
 geweldig ja en we hebben ook de Orville 

00:10:06.060 --> 00:10:10.990
 interactieve ventilatorervaring die dat is 

00:10:08.230 --> 00:10:13.330
 stoomt binnen het volgende paar 

00:10:10.990 --> 00:10:15.520
 van weken zoals de komende is 

00:10:13.330 --> 00:10:18.040
 al op Steam, dus zoek naar de 

00:10:15.520 --> 00:10:20.500
 Orville, dus we kijken er naar zoals sommige 

00:10:18.040 --> 00:10:23.950
 de geweldige sci-fi shows zijn het nu 

00:10:20.500 --> 00:10:26.500
 het zal speelbare VR-spellen zijn, ja dat is het 

00:10:23.950 --> 00:10:29.110
 cool het is erg cool dus kijk uit 

00:10:26.500 --> 00:10:32.470
 bij deze - Bedankt Sasha dat doe je niet 

00:10:29.110 --> 00:10:34.600
 VR een kunstmatig intelligentiesysteem 

00:10:32.470 --> 00:10:37.000
 gemaakt door onderzoekers van de universiteit 

00:10:34.600 --> 00:10:40.960
 van Californië heeft de Rubik's opgelost 

00:10:37.000 --> 00:10:43.990
 Kubus in iets meer dan een seconde diep in een kubus 

00:10:40.960 --> 00:10:46.150
 is het algoritme werd de 3d genoemd 

00:10:43.990 --> 00:10:49.620
 logica puzzel die belastend is geweest 

00:10:46.150 --> 00:10:52.450
 mensen sinds het werd uitgevonden in 1974 

00:10:49.620 --> 00:10:54.640
 professor Pierre Baldy, auteur van de 

00:10:52.450 --> 00:10:58.240
 rapporteer in de natuur machine intelligentie 

00:10:54.640 --> 00:11:00.550
 zei citaat, het leerde het alleen 

00:10:58.240 --> 00:11:01.960
 onderzoekers merkten op dat de strategie was 

00:11:00.550 --> 00:11:04.790
 heel anders dan de manier waarop mensen 

00:11:01.960 --> 00:11:08.210
 pakte de puzzelprofessor Baldy aan 

00:11:04.790 --> 00:11:09.890
 zegt dat mijn beste gok is dat de a-vorm is 

00:11:08.210 --> 00:11:13.070
 van redenering is heel anders 

00:11:09.890 --> 00:11:15.350
 van de unquote van een mens de computer 

00:11:13.070 --> 00:11:17.330
 algoritme is niet de eerste of de 

00:11:15.350 --> 00:11:19.910
 snelste niet-menselijk om de puzzel op te lossen 

00:11:17.330 --> 00:11:21.590
 die eer gaat naar een systeem bedacht om 

00:11:19.910 --> 00:11:24.650
 het Massachusetts Institute of 

00:11:21.590 --> 00:11:27.350
 Technologie noemde de min-tweefasen 

00:11:24.650 --> 00:11:30.860
 algoritme dat de puzzel drie oploste 

00:11:27.350 --> 00:11:32.990
 keer sneller maar dat systeem heeft niet gebruikt 

00:11:30.860 --> 00:11:35.450
 een neuraal netwerk dat bootst hoe het 

00:11:32.990 --> 00:11:37.700
 menselijk brein werkt of machine leert 

00:11:35.450 --> 00:11:39.850
 technieken daarentegen was geprogrammeerd 

00:11:37.700 --> 00:11:42.410
 specifiek om de puzzel op te lossen 

00:11:39.850 --> 00:11:44.510
 een systeem creëren dat zichzelf leert 

00:11:42.410 --> 00:11:46.430
 de uitdaging voltooien wordt gezien als de 

00:11:44.510 --> 00:11:48.260
 eerste stap naar het creëren van een AI die 

00:11:46.430 --> 00:11:49.700
 kan voorbij spellen gaan om op te lossen 

00:11:48.260 --> 00:11:52.010
 echte problemen 

00:11:49.700 --> 00:11:54.740
 hoogleraar kaalvader zegt quote de 

00:11:52.010 --> 00:11:57.140
 oplossing voor de Rubik's Cube omvat 

00:11:54.740 --> 00:11:59.330
 symbolisch wiskundig en abstract 

00:11:57.140 --> 00:12:01.040
 zo een diepe machine denkend dat 

00:11:59.330 --> 00:12:03.500
 kan zo een puzzel breken 

00:12:01.040 --> 00:12:06.740
 dichter bij het worden van een systeem dat dat wel kan 

00:12:03.500 --> 00:12:07.430
 denk reden plan en maak beslissingen te beëindigen 

00:12:06.740 --> 00:12:09.950
 citaat 

00:12:07.430 --> 00:12:11.120
 dit klinkt geweldig, dit is een 

00:12:09.950 --> 00:12:14.870
 interessant verhaal 

00:12:11.120 --> 00:12:17.240
 Ik krijg de reden achter het gebruik ervan 

00:12:14.870 --> 00:12:20.090
 leer een Rubiks kubus op te lossen, maar de 

00:12:17.240 --> 00:12:22.310
 Rubik's Cube is opgelost zoals je gaat 

00:12:20.090 --> 00:12:23.960
 online en je kunt het is alsof dit doen 

00:12:22.310 --> 00:12:26.840
 dit en er is een reeks die je volgt 

00:12:23.960 --> 00:12:29.840
 hoe kan ik het doen ja hoeveel seconden 

00:12:26.840 --> 00:12:31.970
 voor deze machine goed, nee ik begrijp dat 

00:12:29.840 --> 00:12:34.910
 maar het is zo interessant dat het zo is 

00:12:31.970 --> 00:12:38.240
 interessant ja, het leven vindt het zoals het is 

00:12:34.910 --> 00:12:39.560
 een interessante manier om van hoe ze hebben 

00:12:38.240 --> 00:12:43.930
 gebruikte het maar tegelijkertijd ga ik 

00:12:39.560 --> 00:12:47.740
 kiezen iets dat niet is, is opgelost 

00:12:43.930 --> 00:12:47.740
 excuus het punt te missen 

00:12:48.010 --> 00:12:53.990
 ze moeten bewijzen hoe snel het kan oplossen 

00:12:51.620 --> 00:12:56.030
 sommige dingen door het te testen 

00:12:53.990 --> 00:12:57.710
 iets maar ook hoe het oplost 

00:12:56.030 --> 00:13:00.290
 ja, vraag me gewoon een abstracte vraag 

00:12:57.710 --> 00:13:02.810
 stel me een vraag gewoon iets 

00:13:00.290 --> 00:13:05.090
 helemaal buiten de deur, hoeveel 

00:13:02.810 --> 00:13:07.520
 brandstofdeeltjes kom je achter a 

00:13:05.090 --> 00:13:11.600
 jet stream zie ik weet het antwoord niet 

00:13:07.520 --> 00:13:13.190
 Daar heb ik geen idee van en ik kan antwoorden 

00:13:11.600 --> 00:13:14.630
 Goh, je had me er een kunnen vragen 

00:13:13.190 --> 00:13:17.690
 dat ik kon laten mijn antwoord is 

00:13:14.630 --> 00:13:18.529
 dat elke vraag maar het feit hier is 

00:13:17.690 --> 00:13:19.850
 dat is oké 

00:13:18.529 --> 00:13:21.589
 Ik ben gaan zitten met een Rubik's Cube 

00:13:19.850 --> 00:13:24.889
 ja in het huisje omdat je je kent 

00:13:21.589 --> 00:13:27.079
 heb een tijdverdrijf dat dit lui en en is 

00:13:24.889 --> 00:13:27.920
 niet dat niet dat er iets lui is 

00:13:27.079 --> 00:13:29.930
 over een Rubik's Cube 

00:13:27.920 --> 00:13:31.550
 Ik ben echter een intelligente kerel, oh het is 

00:13:29.930 --> 00:13:33.980
 het is goed voor het stimuleren van de hersenen en 

00:13:31.550 --> 00:13:35.930
 Ik ben een intelligente kerel, maar ik denk niet 

00:13:33.980 --> 00:13:37.279
 Ik heb het ooit opgelost, nee, ik denk van wel 

00:13:35.930 --> 00:13:39.470
 op het punt gekomen dat ik rechtvaardig ben 

00:13:37.279 --> 00:13:42.379
 gefrustreerd, ik werd als twee kanten en dat ben ik 

00:13:39.470 --> 00:13:45.649
 zoals dit vergeten trek ik eigenlijk aan de 

00:13:42.379 --> 00:13:46.639
 stukjes uit als een kind Ik addy sticker dip 

00:13:45.649 --> 00:13:49.370
 en lees het 

00:13:46.639 --> 00:13:52.029
 dus beschouw dat alsjeblieft oke, dus gaf ik het op 

00:13:49.370 --> 00:13:54.860
 als een mens ja nu is dit een computer 

00:13:52.029 --> 00:13:57.079
 algoritme aangedreven door AI-technologie a 

00:13:54.860 --> 00:14:00.290
 neuraal net dus het dichtst bij een 

00:13:57.079 --> 00:14:01.790
 neurale net dat we in principe hebben gezien 

00:14:00.290 --> 00:14:03.920
 alsof we deze echt beginnen te zien 

00:14:01.790 --> 00:14:07.720
 dingen, dus ik denk als de luitenant 

00:14:03.920 --> 00:14:10.579
 data begint voor zichzelf te denken dus 

00:14:07.720 --> 00:14:13.279
 hier is de uitdaging, dus ik heb gezegd 

00:14:10.579 --> 00:14:15.499
 deze computer is hier de uitdaging voor jou 

00:14:13.279 --> 00:14:17.180
 moeten de kleuren overeenkomen met alleen maar 

00:14:15.499 --> 00:14:19.069
 over SATA vallen dat ze het hebben verteld 

00:14:17.180 --> 00:14:21.649
 dat is het dat dat is, dat is het 

00:14:19.069 --> 00:14:24.529
 dat is het eindspel en de computer heeft 

00:14:21.649 --> 00:14:27.740
 zei oke boemar boemang 

00:14:24.529 --> 00:14:29.779
 het uit ja en vallen en opstaan ​​en hmm 

00:14:27.740 --> 00:14:30.410
 misschien als ik dit probeer en het uitzoek 

00:14:29.779 --> 00:14:33.079
 rechts 

00:14:30.410 --> 00:14:34.550
 nee en zoals dat is verbazingwekkend het is en het 

00:14:33.079 --> 00:14:36.889
 feit dat ik het deed in iets meer dan een seconde 

00:14:34.550 --> 00:14:38.899
 zoals ik het een seconde krijg, is er geen 

00:14:36.889 --> 00:14:40.399
 het verhaal is net iets langer dan het is 

00:14:38.899 --> 00:14:42.470
 oplosmiddel in iets meer dan een seconde 

00:14:40.399 --> 00:14:44.480
 verbluffend dus opgelost maar het uitgevonden 

00:14:42.470 --> 00:14:46.850
 niet alleen alsof het niet is zoals ze zeiden 

00:14:44.480 --> 00:14:48.230
 Oké, ik ga het programmeren om het te veranderen 

00:14:46.850 --> 00:14:50.360
 op deze manier draai het op die manier draai dat 

00:14:48.230 --> 00:14:53.269
 weg nee, ze zeiden dat dit het is 

00:14:50.360 --> 00:14:56.569
 wat je moet doen om het op te lossen en het 

00:14:53.269 --> 00:14:59.420
 computer ontdekte dat het geweldig is 

00:14:56.569 --> 00:15:02.929
 technologie die de wereld zal veranderen 

00:14:59.420 --> 00:15:04.459
 ja zeker helemaal zo op de op de 

00:15:02.929 --> 00:15:08.740
 positieve kant zeg je ongeveer hetzelfde 

00:15:04.459 --> 00:15:12.410
 technologie hoe kunnen we een oplossing oplossen? 

00:15:08.740 --> 00:15:15.949
 milieucrisis hoe kunnen we de 

00:15:12.410 --> 00:15:19.189
 olie morst uit de de baai rechts en 

00:15:15.949 --> 00:15:20.839
 en het kan dit is het idee is dat 

00:15:19.189 --> 00:15:22.309
 we komen op het punt waarop we 

00:15:20.839 --> 00:15:24.559
 kan dat soort vragen stellen van een 

00:15:22.309 --> 00:15:26.449
 AI van een computer waarvan je denkt dat Google snel is 

00:15:24.559 --> 00:15:27.949
 je denkt dat Google indrukwekkend is met zijn 

00:15:26.449 --> 00:15:28.490
 resultaten dit zal je goed doen 

00:15:27.949 --> 00:15:30.319
 geest 

00:15:28.490 --> 00:15:31.980
 zeker goed het ding met dit verhaal dat 

00:15:30.319 --> 00:15:34.410
 maakt me gaan hmm 

00:15:31.980 --> 00:15:36.569
 een klein beetje is het feit dat het is opgelost 

00:15:34.410 --> 00:15:38.069
 het in een geheel andere logica 

00:15:36.569 --> 00:15:39.600
 patroon dan de manier waarop de mensen ja 

00:15:38.069 --> 00:15:41.220
 en als anders denkt, doet het wat 

00:15:39.600 --> 00:15:44.910
 is prachtig maar als ze er naar op zoek zijn 

00:15:41.220 --> 00:15:47.549
 Laat AI mensen nabootsen om het te laten doen 

00:15:44.910 --> 00:15:49.980
 het werk om dat vervolgens te nemen en goed te gaan 

00:15:47.549 --> 00:15:53.399
 hoe zit het met dit complexe ding dat wij 

00:15:49.980 --> 00:15:55.350
 heb niet kunnen achterhalen leidt tot 

00:15:53.399 --> 00:15:57.419
 logische gedachte die zegt dat het gaat 

00:15:55.350 --> 00:15:58.379
 bedenk een oplossing die we niet kunnen 

00:15:57.419 --> 00:16:01.529
 wikkel onze hoofden rond 

00:15:58.379 --> 00:16:04.589
 dat is de onvermijdelijke vraag hoe 

00:16:01.529 --> 00:16:06.509
 hebben we controle over AI, dus ik zou zeggen de grootste 

00:16:04.589 --> 00:16:07.889
 vraag nu en ik denk dat dat zo is 

00:16:06.509 --> 00:16:09.720
 het hele deel van dit verhaal dat 

00:16:07.889 --> 00:16:11.819
 prikkelt me ​​het meest is dat het dat niet is 

00:16:09.720 --> 00:16:13.350
 over de Rubik's Cube gaat het hierom 

00:16:11.819 --> 00:16:15.929
 is hoe het denkt oke hoe passen we aan 

00:16:13.350 --> 00:16:18.389
 de AI-programmering om te denken zoals wij 

00:16:15.929 --> 00:16:19.799
 wanneer ze dat konden doen, is dat een geheel 

00:16:18.389 --> 00:16:22.139
 niks anders dan game-changer want dan gaat het 

00:16:19.799 --> 00:16:24.449
 hey hoe lossen we de grote vuilnis op 

00:16:22.139 --> 00:16:26.009
 Patch in de Stille Oceaan, dat is dubbel 

00:16:24.449 --> 00:16:28.619
 zo groot als Texas, ga er maar goed over 

00:16:26.009 --> 00:16:31.199
 op deze manier ja alsof er het antwoord is 

00:16:28.619 --> 00:16:33.299
 en toen Martin Ford op de show kwam om 

00:16:31.199 --> 00:16:36.929
 praten over kunstmatige intelligentie en 

00:16:33.299 --> 00:16:38.819
 en waar ze nu zijn als as 

00:16:36.929 --> 00:16:41.220
 een auteur in het veld zoals hij gebruikte 

00:16:38.819 --> 00:16:44.850
 voorbeelden zoals wij doen moeten 

00:16:41.220 --> 00:16:48.569
 begrijp het proces ja dat de AI 

00:16:44.850 --> 00:16:49.860
 gebruikt om de oplossing te vinden die we nodig hebben 

00:16:48.569 --> 00:16:52.529
 om te begrijpen dat we dat ook moeten hebben 

00:16:49.860 --> 00:16:55.470
 controle omdat een eenvoudig verzoek hieromtrent 

00:16:52.529 --> 00:17:00.089
 AI om te zeggen in het voorbeeld dat hij gebruikte 

00:16:55.470 --> 00:17:02.220
 was om ons paperclip-bedrijf meer te maken 

00:17:00.089 --> 00:17:04.529
 efficiënt en dan ineens de 

00:17:02.220 --> 00:17:07.500
 AI neemt het over en en daarmee binnen no 

00:17:04.529 --> 00:17:10.620
 hoe lang ze de AI zijn 

00:17:07.500 --> 00:17:13.230
 hulpbronnen overal vandaan halen en 

00:17:10.620 --> 00:17:15.569
 een efficiënt paperclipbedrijf maken voor 

00:17:13.230 --> 00:17:18.419
 het punt waar nu de menselijke beschaving is 

00:17:15.569 --> 00:17:21.329
 is vernietigd maar paperclips zijn nog steeds 

00:17:18.419 --> 00:17:23.189
 zeer efficiënt gefabriceerd worden wij 

00:17:21.329 --> 00:17:26.909
 moeten de controle hebben die we hebben om het daadwerkelijk te doen 

00:17:23.189 --> 00:17:31.830
 begrijp het proces dat de AI 

00:17:26.909 --> 00:17:33.720
 is denken goed en en je kunt krijgen 

00:17:31.830 --> 00:17:35.519
 onze hoofden rond dat wat nu moeilijk is 

00:17:33.720 --> 00:17:37.740
 degene die je kent als ze niet denken 

00:17:35.519 --> 00:17:38.820
 zoals wij, ik ben het ermee eens dat je weet dat we de 

00:17:37.740 --> 00:17:39.840
 chatroomgeld waar we het over hebben 

00:17:38.820 --> 00:17:41.549
 dit en het eten brengen een nieuw naar voren 

00:17:39.840 --> 00:17:43.720
 De vraag is hoe vaak de AI was 

00:17:41.549 --> 00:17:45.760
 moet eerst de puzzel oplossen 

00:17:43.720 --> 00:17:48.549
 dat zou interessant zijn om te weten of dat het was 

00:17:45.760 --> 00:17:50.740
 een simpele oh dit is de situatie die ik 

00:17:48.549 --> 00:17:51.970
 moet wat scheten laten lopen oke ja of deed het 

00:17:50.740 --> 00:17:54.429
 eigenlijk door vallen en opstaan ​​dat 

00:17:51.970 --> 00:17:56.530
 Ik zou interessant zijn om te weten dat ik dat zou doen 

00:17:54.429 --> 00:17:57.970
 stel je voor als en we hebben niet de 

00:17:56.530 --> 00:17:59.830
 antwoord hiermee en het staat niet in de 

00:17:57.970 --> 00:18:01.870
 nieuws, maar ik kan me voorstellen dat het zo is 

00:17:59.830 --> 00:18:03.789
 a het leerde het en toen was het in staat om 

00:18:01.870 --> 00:18:06.340
 los het beter op nadat ik het heb geleerd 

00:18:03.789 --> 00:18:09.700
 denk niet dat die ene seconde inbegrepen is 

00:18:06.340 --> 00:18:11.169
 het leren en uitzoeken hoe maar 

00:18:09.700 --> 00:18:13.059
 toen het werd gepresenteerd 

00:18:11.169 --> 00:18:16.750
 hebben geleerd hoe om te gaan met a 

00:18:13.059 --> 00:18:19.000
 Rubik's Cube als een menselijk kind jij 

00:18:16.750 --> 00:18:22.150
 zou zo kunnen bewegen op deze manier en 

00:18:19.000 --> 00:18:24.220
 op die manier kost het tijd oh ja ja oh 

00:18:22.150 --> 00:18:25.900
 je zou het wat moeten leren, maar het is a 

00:18:24.220 --> 00:18:31.000
 goede vraag, zodat we zullen poseren 

00:18:25.900 --> 00:18:34.900
 dat voor de a zal ik het Intel vragen 

00:18:31.000 --> 00:18:38.080
 onthulde zijn nieuwe AI-systeem Pahokee-strand 

00:18:34.900 --> 00:18:40.539
 het is een neurale morph-computer 

00:18:38.080 --> 00:18:43.630
 in staat om acht miljoen te simuleren 

00:18:40.539 --> 00:18:45.750
 neuronen neuromorfe engineering ook 

00:18:43.630 --> 00:18:48.429
 bekend als neuromorfische computing 

00:18:45.750 --> 00:18:51.340
 beschrijft het gebruik van systemen met 

00:18:48.429 --> 00:18:53.919
 elektronische analoge schakelingen om na te bootsen 

00:18:51.340 --> 00:18:56.440
 neurobiologische architectuur in de 

00:18:53.919 --> 00:18:58.480
 aanwezig zenuwstelsel het doel van 

00:18:56.440 --> 00:19:00.400
 neuromorfisch onderzoek is het bereiken van een 

00:18:58.480 --> 00:19:03.640
 supercomputer duizend keer meer 

00:19:00.400 --> 00:19:06.190
 krachtig dan welke dag dan ook tijdens de DARPA 

00:19:03.640 --> 00:19:09.340
 heropleving van het initiatief op het gebied van elektronica 

00:19:06.190 --> 00:19:11.020
 in Detroit op maandag onthulde Intel een 64 

00:19:09.340 --> 00:19:14.860
 chipcomputer die kan simuleren 

00:19:11.020 --> 00:19:17.940
 acht miljoen neuronen in totaal Intel 

00:19:14.860 --> 00:19:20.919
 Labs managing director rijke uhlig gezegd 

00:19:17.940 --> 00:19:23.710
 Pahokee Beach zal ter beschikking worden gesteld aan 

00:19:20.919 --> 00:19:26.140
 zestig onderzoekspartners om vooruitgang te melden 

00:19:23.710 --> 00:19:29.049
 het veld einde citaat en schaal AI 

00:19:26.140 --> 00:19:35.169
 algoritmen zoals vrije codering en pad 

00:19:29.049 --> 00:19:38.230
 planning pokey Strandpakket 64 low key 128 

00:19:35.169 --> 00:19:40.600
 kern 14 nanometer en neuromorfe chips 

00:19:38.230 --> 00:19:46.150
 welke de eerste waren die in oktober werd gedetailleerd 

00:19:40.600 --> 00:19:49.659
 2017 elke onderste loi-processor heeft een 60 

00:19:46.150 --> 00:19:53.380
 millimeter sterven en bevatten meer dan twee 

00:19:49.659 --> 00:19:55.190
 miljard transistors 130.000 kunstmatig 

00:19:53.380 --> 00:19:57.950
 neuronen en 100 

00:19:55.190 --> 00:20:00.290
 en 30 miljoen synapsen naast 

00:19:57.950 --> 00:20:03.320
 drie die Lake menthe-kernen beheren voor 

00:20:00.290 --> 00:20:07.130
 taakorkestratie volgens Intel 

00:20:03.320 --> 00:20:09.020
 Loy hij verwerkt informatie tot 1.000 

00:20:07.130 --> 00:20:11.810
 keer sneller en 10.000 keer meer 

00:20:09.020 --> 00:20:13.760
 efficiënter dan traditionele processors 

00:20:11.810 --> 00:20:15.800
 en het kan bepaalde soorten oplossen 

00:20:13.760 --> 00:20:18.770
 optimalisatieproblemen met meer dan 

00:20:15.800 --> 00:20:21.230
 drie orden van grootte winst in snelheid 

00:20:18.770 --> 00:20:24.140
 en energie-efficiëntie in vergelijking met 

00:20:21.230 --> 00:20:26.690
 conventionele CPU-bewerkingen de chip 

00:20:24.140 --> 00:20:29.660
 verbruikt ongeveer 100 keer minder energie 

00:20:26.690 --> 00:20:33.140
 dan veel gebruikte CPU-run-simulatie 

00:20:29.660 --> 00:20:35.240
 locatie- en mappingmethoden, zegt Intel 

00:20:33.140 --> 00:20:38.810
 dat dat later dit jaar zal worden geïntroduceerd 

00:20:35.240 --> 00:20:42.380
 een nog groter llahi-systeem Pahokee 

00:20:38.810 --> 00:20:44.750
 Veren die een unquote leveren 

00:20:42.380 --> 00:20:47.240
 ongekend een niveau van prestaties en 

00:20:44.750 --> 00:20:52.910
 efficiëntie voor neuromorfe werkbelastingen 

00:20:47.240 --> 00:20:54.410
 met meer dan 100 miljoen neuronen maar 

00:20:52.910 --> 00:20:57.200
 ze bedekten niet wat het giechelen scoorde 

00:20:54.410 --> 00:20:59.210
 is ja drie punten die je nog herinnert 

00:20:57.200 --> 00:21:04.850
 toen de processors heel vriendelijk waren 

00:20:59.210 --> 00:21:08.680
 namen als Pentium Celeron is het zo goed 

00:21:04.850 --> 00:21:12.590
 alles gedaan is als een vreemd woord 

00:21:08.680 --> 00:21:15.500
 het is echt moeilijk, maar je begrijpt het 

00:21:12.590 --> 00:21:19.580
 ervan - wanneer kunnen we onze crypto toevoegen 

00:21:15.500 --> 00:21:23.780
 mijnwerkers om dit ja en ja ik bedoel 

00:21:19.580 --> 00:21:24.980
 derde vraag is zoals en dat is het niet 

00:21:23.780 --> 00:21:27.290
 echt een vraag maar meer een 

00:21:24.980 --> 00:21:30.280
 verklaring zien hoe technologie heeft 

00:21:27.290 --> 00:21:33.860
 vorderde en hoorde dat nu 

00:21:30.280 --> 00:21:39.470
 processors worden in termen beschreven 

00:21:33.860 --> 00:21:42.890
 van neuronen en positronen zoals dit is 

00:21:39.470 --> 00:21:47.330
 het spul van Star Trek is zoals we zijn 

00:21:42.890 --> 00:21:54.610
 een brein praten dit is een brein op 8 

00:21:47.330 --> 00:22:00.650
 miljoen, wat zijn het acht miljoen neuronen 

00:21:54.610 --> 00:22:03.230
 dus we zijn wat een miljard ik denk dat het is a 

00:22:00.650 --> 00:22:06.800
 beter brein dan we hebben geen nee oh god 

00:22:03.230 --> 00:22:08.900
 nee nee het is sneller ik ken ze niet zo 

00:22:06.800 --> 00:22:11.510
 ja nee dit is niets vergeleken 

00:22:08.900 --> 00:22:15.230
 een menselijk brein maar weer terug naar 

00:22:11.510 --> 00:22:17.780
 wetende dat die computers aan het opstarten zijn 

00:22:15.230 --> 00:22:20.570
 om na te denken ja en dat zijn ze nu 

00:22:17.780 --> 00:22:22.520
 ze bouwen een brein op van de computer 

00:22:20.570 --> 00:22:25.300
 chips wat ik nu wil weten is 

00:22:22.520 --> 00:22:27.440
 hoe is dit te vergelijken met Watson Oh 

00:22:25.300 --> 00:22:31.250
 Watson zou niets zijn vergeleken met dit 

00:22:27.440 --> 00:22:34.460
 goed, we praten zoals in het verhaal 

00:22:31.250 --> 00:22:38.540
 praten over hoe dit kan zijn duizend 

00:22:34.460 --> 00:22:41.840
 keer sneller dan welke supercomputer dan ook 

00:22:38.540 --> 00:22:42.980
 bestaat vandaag precies in onze ik figuur hoe 

00:22:41.840 --> 00:22:45.080
 veel is in de nabije toekomst 

00:22:42.980 --> 00:22:46.370
 Watson ja dat is alles wat we gaan doen 

00:22:45.080 --> 00:22:50.960
 doe dit en door de manier waarop het echt gaat 

00:22:46.370 --> 00:22:53.150
 beter worden door de fout ja dus nogmaals vragen 

00:22:50.960 --> 00:22:55.700
 die vraag hoe kunnen we de wereld oplossen 

00:22:53.150 --> 00:23:00.020
 honger, weet je, antwoord me gewoon 

00:22:55.700 --> 00:23:02.990
 nou ja, in de eerste plaats ja ik heb er een die ik heb 

00:23:00.020 --> 00:23:04.130
 een paar suggesties, dus het gaat het 

00:23:02.990 --> 00:23:07.220
 gaat helpen met dat soort dingen 

00:23:04.130 --> 00:23:09.740
 als het in de juiste handen is mm-hmm en 

00:23:07.220 --> 00:23:11.900
 dat is dat het gewoon gek is alsof ik gewoon ben 

00:23:09.740 --> 00:23:14.600
 Ik ben absoluut verbouwereerd op het punt 

00:23:11.900 --> 00:23:17.060
 van tong-gebonden omdat ik alles stopte 

00:23:14.600 --> 00:23:19.250
 zoals dit in de context van data omdat 

00:23:17.060 --> 00:23:22.450
 en data het Star Trek-personage 

00:23:19.250 --> 00:23:25.730
 omdat dat een positronic net is dat een is 

00:23:22.450 --> 00:23:28.870
 neuromorfische computer goed en nu 

00:23:25.730 --> 00:23:31.840
 we zijn in orde oke dit is als stip 

00:23:28.870 --> 00:23:34.580
 zoals dit is het rudimentaire 

00:23:31.840 --> 00:23:37.220
 inleidende versie van haat die ze hebben 

00:23:34.580 --> 00:23:38.870
 de AI-technologie nu, zodat het kan denken 

00:23:37.220 --> 00:23:40.970
 voor zichzelf kan het leren hoe een a op te lossen 

00:23:38.870 --> 00:23:42.860
 Rubik's Cube in een seconde en we hebben 

00:23:40.970 --> 00:23:45.950
 de technologie om het snel te maken en te maken 

00:23:42.860 --> 00:23:51.020
 het om in een heel erg te kunnen denken 

00:23:45.950 --> 00:23:53.390
 snelle manier, zodat je net als bij tech werkt 

00:23:51.020 --> 00:23:55.790
 ja en je doet veel, werk niet in een 

00:23:53.390 --> 00:23:57.560
 Ik vind dit spul leuk, net als het mijne 

00:23:55.790 --> 00:23:59.810
 je doet veel servicegesprekken en like 

00:23:57.560 --> 00:24:03.110
 gekleurde mensen kun je je voorstellen als 

00:23:59.810 --> 00:24:05.480
 er was een AI die als een micro concurreerde 

00:24:03.110 --> 00:24:08.900
 versie hiervan die uw bedrijf heeft gekocht 

00:24:05.480 --> 00:24:11.800
 mmm die het mogelijk maakte om VPN te gebruiken in mensen 

00:24:08.900 --> 00:24:13.700
 thuiscomputers om hun probleem op te lossen 

00:24:11.800 --> 00:24:15.980
 automatisch voor hen kunt u zich voorstellen 

00:24:13.700 --> 00:24:18.290
 hoe dat je branche mmm zou veranderen 

00:24:15.980 --> 00:24:20.810
 er is veel in mijn branche dat is 

00:24:18.290 --> 00:24:21.990
 overbodig en daarmee bedoel ik dat het zo is 

00:24:20.810 --> 00:24:24.990
 repetitieve ja 

00:24:21.990 --> 00:24:26.190
 het is altijd hetzelfde, maar ik denk 

00:24:24.990 --> 00:24:29.100
 je neemt zoiets als ze kunnen gaan 

00:24:26.190 --> 00:24:31.620
 zoals dat, ja, zoals hoe en kan ik praten 

00:24:29.100 --> 00:24:34.340
 bedoel, praat met je Amazon-echo en wees 

00:24:31.620 --> 00:24:37.410
 alsof het klinkt als een persoon die het doet 

00:24:34.340 --> 00:24:39.750
 ze kunnen praten, zodat je het weet 

00:24:37.410 --> 00:24:42.480
 er zijn allerlei onheilspellende dingen hier 

00:24:39.750 --> 00:24:44.520
 maar als dit in de juiste handen is, kan dit een zijn 

00:24:42.480 --> 00:24:47.070
 zeer krachtige tool voor goed dus 

00:24:44.520 --> 00:24:49.410
 dit is zojuist onthuld en 

00:24:47.070 --> 00:24:54.030
 ontwikkelde maar autonome voertuigen zijn dat wel 

00:24:49.410 --> 00:24:56.700
 al daarbuiten, juist ja nee nee maar 

00:24:54.030 --> 00:25:00.720
 via internet zeer WiFi via 

00:24:56.700 --> 00:25:04.800
 LTE of 5g of wat je maar wilt doen 

00:25:00.720 --> 00:25:06.660
 het is alsof het altijd verbonden is, ja 

00:25:04.800 --> 00:25:08.520
 nu heb je ineens zoiets 

00:25:06.660 --> 00:25:11.700
 van een brein dat het neurale netwerk aandrijft 

00:25:08.520 --> 00:25:13.740
 van autonome voertuigen oké jij ook 

00:25:11.700 --> 00:25:15.210
 onthoud dat ik ga zeggen: jaar en a 

00:25:13.740 --> 00:25:16.500
 elke twee jaar geleden. we weet het niet 

00:25:15.210 --> 00:25:18.300
 als er een nieuwsbericht is maar wat we hebben 

00:25:16.500 --> 00:25:19.530
 sprak over een ton voertuigen en ik 

00:25:18.300 --> 00:25:21.570
 zei zou het niet geweldig zijn als we kunnen 

00:25:19.530 --> 00:25:25.020
 ga naar het punt waar het verkeer 

00:25:21.570 --> 00:25:27.270
 beheer via verbonden auto's is het 

00:25:25.020 --> 00:25:29.429
 onmiddellijk waar het op gebaseerd is 

00:25:27.270 --> 00:25:30.480
 rijpatronen van mensen hun werk 

00:25:29.429 --> 00:25:32.010
 uren ja 

00:25:30.480 --> 00:25:33.270
 hun schema aflezen en dat zijn we nu 

00:25:32.010 --> 00:25:34.860
 tot privacy en allerlei dingen komen 

00:25:33.270 --> 00:25:36.120
 maar je weet zeker dat je weet dat je moet lezen 

00:25:34.860 --> 00:25:38.040
 uw Google Conner waar u zou moeten 

00:25:36.120 --> 00:25:40.140
 be Drive time to go je moet het verlaten 

00:25:38.040 --> 00:25:41.610
 deze keer trouwens die uitgang nemen 

00:25:40.140 --> 00:25:44.460
 exit en er is ergens een computer 

00:25:41.610 --> 00:25:46.620
 dat routeert al deze autonome auto's 

00:25:44.460 --> 00:25:48.570
 dat is alsof je gewoon gaat Ik ben goed dit 

00:25:46.620 --> 00:25:51.179
 moment en ze maken vliegende taxi's 

00:25:48.570 --> 00:25:55.320
 ja en voeg dat toe aan de mix 

00:25:51.179 --> 00:25:58.770
 je hebt geen reden om te laat te zijn 

00:25:55.320 --> 00:26:01.800
 computer gemaakt op tijd dat is geweldig 

00:25:58.770 --> 00:26:03.929
 hallo laten we even kijken naar de 

00:26:01.800 --> 00:26:06.630
 cryptocurrency markt zo is het 

00:26:03.929 --> 00:26:09.540
 kijkt hier in 2019 voor het neurale 

00:26:06.630 --> 00:26:12.030
 netwerk stelt ons in staat enorm te mijnen 

00:26:09.540 --> 00:26:15.179
 hoeveelheden Bitcoin dus meteen 

00:26:12.030 --> 00:26:17.220
 Bitcoin zit op 9700 twee en negentig 

00:26:15.179 --> 00:26:20.220
 dollars en 67 cent zeg ik maar 

00:26:17.220 --> 00:26:24.120
 alles is naar beneden Bitcoin Bitcoin verliezen 

00:26:20.220 --> 00:26:27.420
 hoewel het de grootste verliezer is van 2137 

00:26:24.120 --> 00:26:30.540
 dollars en 35 cent in de - van de laatste 

00:26:27.420 --> 00:26:31.980
 week waarop Facebook Libre nog steeds zit 

00:26:30.540 --> 00:26:33.570
 nul dollar en ik ga houden 

00:26:31.980 --> 00:26:35.200
 je vertellen dat omdat het op een dag is 

00:26:33.570 --> 00:26:36.789
 zal een cent waard zijn 

00:26:35.200 --> 00:26:38.919
 en dat is wanneer we dat weten 

00:26:36.789 --> 00:26:41.019
 Facebook doet eigenlijk wat ze doen 

00:26:38.919 --> 00:26:42.549
 zeiden dat ze litecoin aan het doen zijn 

00:26:41.019 --> 00:26:46.510
 eenennegentig dollar en drie cent naar beneden 

00:26:42.549 --> 00:26:47.980
 zestien en 72 cent etherium om twee uur 

00:26:46.510 --> 00:26:50.919
 honderd en dertien dollar en 72 

00:26:47.980 --> 00:26:53.769
 cent monaro om zeven en zeventig negenenvijftig 

00:26:50.919 --> 00:26:56.440
 nu is het koppel op nul punt negen zes tien 

00:26:53.769 --> 00:26:59.169
 duizendste cent en schildpadmunt 

00:26:56.440 --> 00:27:00.669
 ook verliezen op het nulpunt negen acht tien 

00:26:59.169 --> 00:27:01.809
 duizendste cent weet niet meer of 

00:27:00.669 --> 00:27:04.600
 je gaat de mijne als je gaat 

00:27:01.809 --> 00:27:06.909
 investeren of anderszins werken 

00:27:04.600 --> 00:27:09.250
 cryptocurrency het is een markt die nooit 

00:27:06.909 --> 00:27:11.919
 sluit en het is een markt die altijd is 

00:27:09.250 --> 00:27:15.510
 vluchtig dus wees voorzichtig en alleen spenderen 

00:27:11.919 --> 00:27:18.460
 investeer alleen waar u het zich kunt veroorloven om te verliezen 

00:27:15.510 --> 00:27:19.990
 grote dank aan Roy W Nash en onze 

00:27:18.460 --> 00:27:21.880
 community van kijkers voor inzending 

00:27:19.990 --> 00:27:23.950
 verhalen voor ons deze week bedankt voor 

00:27:21.880 --> 00:27:25.960
 het bekijken van de nieuws-tv van categorie vijf 

00:27:23.950 --> 00:27:27.909
 vergeet niet te liken en abonneer voor 

00:27:25.960 --> 00:27:29.769
 al je technieuws met een beetje Linux 

00:27:27.909 --> 00:27:31.510
 bias en voor meer gratis inhoud zeker 

00:27:29.769 --> 00:27:33.730
 om onze website te bekijken van de 

00:27:31.510 --> 00:27:35.860
 category-five TV newsroom Ik ben Sasha 

00:27:33.730 --> 00:27:38.309
 Rickman en ik zijn Robbie Ferguson en ik 

00:27:35.860 --> 00:27:38.309
 Jeff Lester 

00:27:42.860 --> 00:27:48.640
 [Muziek] 

00:27:46.560 --> 00:27:58.640
 [Applaus] 

00:27:48.640 --> 00:27:58.640
 [Muziek] 

