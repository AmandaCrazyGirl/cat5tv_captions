WEBVTT
Kind: captions
Language: ur

00:00:01.100 --> 00:00:07.379
 ہفتہ کی اعلی نصابی کتب کا احاطہ جیسے لینکس پر تعصب فیس بک نے ایک نئی شروعات کی ہے 

00:00:07.379 --> 00:00:11.190
 چیٹ بوٹ جس کا یہ دعوی کرتا ہے وہ ہمدردی کے علم کا مظاہرہ کرنے میں اہل ہے اور 

00:00:11.190 --> 00:00:16.800
 شخصیت ان کے چیٹ بوٹ جس کو انہوں نے پریشان کن نامزد کیا ہے اس کی تربیت دی گئی تھی 

00:00:16.800 --> 00:00:21.090
 دستیاب عوامی ڈومین گفتگو کا استعمال جس میں 1.5 بلین شامل ہیں 

00:00:21.090 --> 00:00:26.400
 انسانی تبادلے کی مثالیں لیکن ماہرین کا کہنا ہے کہ مصنوعی ذہانت کی تربیت کرنا 

00:00:26.400 --> 00:00:31.740
 پلیٹ فارم جیسے reddit کو استعمال کرنے سے اس کی خامیاں ہوتی ہیں جس کے دوران متعدد مسائل پیدا ہوئے 

00:00:31.740 --> 00:00:35.910
 لمبی بات چیت کرنے والا بلینڈر کبھی کبھی اشتعال انگیز ہوتا تھا 

00:00:35.910 --> 00:00:40.559
 زبان اور دوسرے اوقات میں یہ محققین کے سامنے حقائق بناتے ہیں 

00:00:40.559 --> 00:00:44.270
 انہوں نے کہا کہ انہیں امید ہے کہ مزید ماڈل ان مسائل کو حل کریں گے 

00:00:44.270 --> 00:00:49.200
 مصنوعی ذہانت کے ماہر ڈیو چوپین نے کہا کہ بلینڈر ایک قدم تھا 

00:00:49.200 --> 00:00:52.890
 صحیح سمت لیکن دو بنیادی امور کو نوٹ کیا جو ابھی باقی رہنے کی ضرورت ہے 

00:00:52.890 --> 00:00:58.079
 اس نے بی بی سی کو بتایا کہ سب سے پہلے اس کی نقل تیار کرنا کتنا پیچیدہ ہے 

00:00:58.079 --> 00:01:03.570
 کسی انسان کی خصوصیت کی باریکی کے بارے میں جیسے گفتگو کو گھونٹ ڈالنے کی صلاحیت 

00:01:03.570 --> 00:01:07.500
 ایک مہارت جس میں زیادہ تر تین سالہ بچے دوسرے کو ماہر کرسکتے ہیں اس کے آس پاس ہے 

00:01:07.500 --> 00:01:11.670
 ماڈل کی تربیت کے لئے استعمال ہونے والے اعداد و شمار اور اس کے نتیجے میں پیدا ہونے والے نتائج سے رشتہ 

00:01:11.670 --> 00:01:17.009
 جس ماڈل پر یہ وضاحت کرنے کے لئے چلا جاتا ہے جتنا ایک پلیٹ فارم ریٹٹا کی تربیت ہے 

00:01:17.009 --> 00:01:20.790
 آپ کو جو بات چیت ملتی ہے اس کی بنیاد پر الگورتھم آپ کو بہت کچھ ملتا ہے 

00:01:20.790 --> 00:01:25.740
 فیس بک نے بھی گندم کے مابین بھوسی کی آمیزش کی ہے 

00:01:25.740 --> 00:01:31.200
 گوگل کی اپنی چیٹ BOTS Mina کا تازہ ترین ورژن اس میں لوگوں کو دو سیٹ دکھائے گئے 

00:01:31.200 --> 00:01:35.340
 ایک گفتگو کے ساتھ بلینڈر اور دوسرا مینا کی گفتگو سے 

00:01:35.340 --> 00:01:39.860
 فلموں میں موسیقی اور ویگنزم سمیت متعدد موضوعات شامل تھے 

00:01:39.860 --> 00:01:45.090
 فیس بک نے کہا کہ بلینڈر کے ذریعہ 67 فیصد جواب دہندگان اس سے زیادہ انسانی لگتے ہیں 

00:01:45.090 --> 00:01:50.399
 مینا محققین نے نوٹ کیا کہ ہم نے ایک نیا چیٹ بوٹ کے ذریعے یہ سنگ میل حاصل کیا 

00:01:50.399 --> 00:01:54.990
 ایسی ترکیب جس میں ضابطہ بندی کی بہتر تکنیکوں کی مہارت کی جدید ملاوٹ شامل ہوتی ہے اور 

00:01:54.990 --> 00:01:59.490
 نو پوائنٹ چار ارب پیرامیٹرز والا ایک ماڈل جو تین پوائنٹ چھ ہے 

00:01:59.490 --> 00:02:04.380
 واقعی ذہین کی تعمیر کرنے والے سب سے بڑے موجودہ نظام سے کہیں زیادہ 

00:02:04.380 --> 00:02:08.399
 بات چیت کرنے والا ایجنٹ جو انسان کی طرح چیٹ کرسکتا ہے وہ اب بھی سب سے زیادہ کھلا رہتا ہے 

00:02:08.399 --> 00:02:12.410
 آج میں AI میں چیلنجز 

00:02:23.240 --> 00:02:26.279
 [موسیقی] 

